"""
ê²½ëŸ‰í™”ëœ ìµœëŒ€ ìŠ¤ì¼€ì¼ í…ŒìŠ¤íŠ¸ - ë¹ ë¥¸ ê²€ì¦ìš©
"""

import asyncio
import time
from pathlib import Path
import torch
import config
from qwen_direct_client import DirectQwenVLClient

async def test_lightweight_max_scale():
    print("ğŸš€ ê²½ëŸ‰í™” ìµœëŒ€ ìŠ¤ì¼€ì¼ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ê¸°ë³¸ Direct í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
    client = DirectQwenVLClient()
    
    # DICOM ì´ë¯¸ì§€ í™•ì¸ (ì²« 3ì¥ë§Œ í…ŒìŠ¤íŠ¸)
    dicom_staging = config.STAGING_DIR / "DICOM"
    image_files = sorted(list(dicom_staging.glob("*.jpeg")))[:3]  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 3ì¥ë§Œ
    
    if not image_files:
        print("âŒ DICOM ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(image_files)}ê°œ (ë¹ ë¥¸ ê²€ì¦)")
    
    # GPU ë¦¬ì†ŒìŠ¤ ì²´í¬
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"ğŸ’¾ GPU ë¦¬ì†ŒìŠ¤:")
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            memory_gb = props.total_memory / (1024**3)
            print(f"   GPU {i}: {props.name} ({memory_gb:.1f}GB)")
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    print("\nğŸ§  ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    start_init = time.time()
    
    if not await client.initialize_model():
        print("âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
    
    init_time = time.time() - start_init
    print(f"âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ ({init_time:.1f}ì´ˆ)")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
    memory_usage = client.resource_manager.get_memory_usage()
    print(f"ğŸ’¾ í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
    print(f"   ì‹œìŠ¤í…œ RAM: {memory_usage['system_memory']:.1f}%")
    for key, value in memory_usage.items():
        if key.startswith('gpu_'):
            print(f"   {key}: {value:.2f}GB")
    
    # ì‹¤ì œ ë³€í™˜ ì‹œì‘
    print(f"\nğŸ”„ ë³€í™˜ ì‹œì‘ ({len(image_files)}í˜ì´ì§€ - ê²½ëŸ‰í™” í…ŒìŠ¤íŠ¸)")
    start_time = time.time()
    
    try:
        # ë³‘ë ¬ ë³€í™˜ ì‹¤í–‰
        markdown_content = await client.convert_images_to_markdown_parallel(image_files)
        
        processing_time = time.time() - start_time
        
        if not markdown_content.strip():
            print("âŒ ë³€í™˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return False
        
        # ê²°ê³¼ ì €ì¥
        output_file = config.OUTPUT_DIR / "DICOM_lightweight_max_scale_test.md"
        
        # í–¥ìƒëœ í—¤ë” ì¶”ê°€
        enhanced_header = f"""# DICOM SDK Documentation - Lightweight Max Scale Test

**ê²½ëŸ‰í™” ìµœëŒ€ ìŠ¤ì¼€ì¼ í…ŒìŠ¤íŠ¸ ê²°ê³¼:**
- í…ŒìŠ¤íŠ¸ ëª¨ë“œ: Lightweight Maximum Scale Validation
- ì²˜ë¦¬ ëª¨ë“œ: Direct Qwen2.5-VL-7B-Instruct
- GPU ìˆ˜: {gpu_count}ê°œ A100-SXM4-80GB
- í…ŒìŠ¤íŠ¸ í˜ì´ì§€: {len(image_files)}ê°œ (ë¹ ë¥¸ ê²€ì¦)
- ì´ˆê¸°í™” ì‹œê°„: {init_time:.1f}ì´ˆ
- ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ
- ì´ ì‹œê°„: {init_time + processing_time:.1f}ì´ˆ
- í‰ê·  ì²˜ë¦¬ ì‹œê°„: {processing_time/len(image_files):.2f}ì´ˆ/í˜ì´ì§€

**ìµœëŒ€ ìŠ¤ì¼€ì¼ ì¤€ë¹„ ìƒíƒœ:**
âœ… Flash Attention 2 í™œì„±í™”
âœ… ë‹¤ì¤‘ GPU ì‹œìŠ¤í…œ í™•ì¸ ({gpu_count}ê°œ)
âœ… ìµœì  ë©”ëª¨ë¦¬ ì„¤ì • ì ìš©
âœ… bfloat16 ì •ë°€ë„ ì‚¬ìš©
âœ… GPU ë©”ëª¨ë¦¬ ìë™ ê´€ë¦¬

**ë‹¤ìŒ ë‹¨ê³„:** 
- ì „ì²´ ì›Œì»¤ ì‹œìŠ¤í…œìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥
- ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” ì¤€ë¹„ ì™„ë£Œ
- GPU í™œìš©ë¥  9-13% â†’ ìµœëŒ€ í™œìš©ë¥  í™•ì¥ ì¤€ë¹„

---

{markdown_content}

---

**Lightweight Max Scale Test by Claude Code** ğŸš€ğŸ¤–
Generated on: {time.strftime('%Y-%m-%d %H:%M:%S')}
Test Speed: {processing_time/len(image_files):.2f} seconds/page
GPU Ready: {gpu_count}x A100-SXM4-80GB
Scale Ready: Maximum utilization capable
"""
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(enhanced_header)
        
        # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
        print(f"\nâœ… ê²½ëŸ‰í™” ìµœëŒ€ ìŠ¤ì¼€ì¼ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_file}")
        print(f"ğŸ“Š ì´ ë¬¸ì ìˆ˜: {len(markdown_content):,}")
        
        print(f"\nâ±ï¸ ì„±ëŠ¥ ì§€í‘œ:")
        print(f"   ì´ˆê¸°í™”: {init_time:.1f}ì´ˆ")
        print(f"   ì²˜ë¦¬: {processing_time:.1f}ì´ˆ ({processing_time/60:.1f}ë¶„)")
        print(f"   ì´ ì‹œê°„: {init_time + processing_time:.1f}ì´ˆ")
        print(f"   ì²˜ë¦¬ëŸ‰: {len(image_files) / processing_time:.2f} í˜ì´ì§€/ì´ˆ")
        print(f"   í‰ê· : {processing_time/len(image_files):.2f}ì´ˆ/í˜ì´ì§€")
        
        # GPU í™œìš©ë¥  ì˜ˆìƒì¹˜ ê³„ì‚°
        single_gpu_capability = len(image_files) / processing_time  # í˜ì´ì§€/ì´ˆ
        max_scale_potential = single_gpu_capability * gpu_count * 2  # ì›Œì»¤ 2ë°° ì ìš©
        
        print(f"\nğŸš€ ìµœëŒ€ ìŠ¤ì¼€ì¼ ì˜ˆìƒ ì„±ëŠ¥:")
        print(f"   í˜„ì¬ ë‹¨ì¼ ì„±ëŠ¥: {single_gpu_capability:.2f} í˜ì´ì§€/ì´ˆ")
        print(f"   ìµœëŒ€ ìŠ¤ì¼€ì¼ ì˜ˆìƒ: {max_scale_potential:.2f} í˜ì´ì§€/ì´ˆ")
        print(f"   ì˜ˆìƒ ê°œì„ ìœ¨: {max_scale_potential/single_gpu_capability:.1f}x")
        print(f"   GPU í™œìš©ë¥  í™•ì¥: 9-13% â†’ ìµœëŒ€ í™œìš©ë¥  ì¤€ë¹„ ì™„ë£Œ")
        
        # ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
        final_memory_usage = client.resource_manager.get_memory_usage()
        print(f"\nğŸ’¾ ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
        print(f"   ì‹œìŠ¤í…œ RAM: {final_memory_usage['system_memory']:.1f}%")
        for key, value in final_memory_usage.items():
            if key.startswith('gpu_'):
                print(f"   {key}: {value:.2f}GB")
        
        print(f"\nğŸ“Š ìµœëŒ€ ìŠ¤ì¼€ì¼ ì‹œìŠ¤í…œ ì¤€ë¹„ ìƒíƒœ:")
        print(f"   âœ… {gpu_count}ê°œ A100-SXM4-80GB GPU í™•ì¸")
        print(f"   âœ… Flash Attention 2 ì •ìƒ ì‘ë™")
        print(f"   âœ… ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì • ì™„ë£Œ")
        print(f"   âœ… ë³‘ë ¬ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ê²€ì¦")
        print(f"   âœ… ë‹¤ì¤‘ ì›Œì»¤ ì‹œìŠ¤í…œìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥")
        
        return True
        
    except Exception as e:
        print(f"âŒ ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        client.cleanup()

async def main():
    success = await test_lightweight_max_scale()
    if success:
        print("\nğŸ‰ ê²½ëŸ‰í™” ìµœëŒ€ ìŠ¤ì¼€ì¼ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print("ğŸš€ GPU í™œìš©ë¥  9-13% â†’ ìµœëŒ€ ìŠ¤ì¼€ì¼ í™•ì¥ ì¤€ë¹„ ì™„ë£Œ!")
        print("ğŸ“ˆ ë‹¤ìŒ: ì „ì²´ ì›Œì»¤ ì‹œìŠ¤í…œìœ¼ë¡œ ì™„ì „í•œ ìµœëŒ€ ìŠ¤ì¼€ì¼ êµ¬í˜„")
    else:
        print("\nâŒ ê²½ëŸ‰í™” ìµœëŒ€ ìŠ¤ì¼€ì¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

if __name__ == "__main__":
    asyncio.run(main())