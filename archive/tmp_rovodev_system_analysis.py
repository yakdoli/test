#!/usr/bin/env python3
"""
ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë¶„ì„ ë° Ollama ì²˜ë¦¬ ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸
CPU ì½”ì–´ ìˆ˜ ê¸°ë°˜ ìµœì  ì›Œì»¤ ì„¤ì • í™•ì¸
"""
import os
import psutil
import time
import threading
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import sys
sys.path.append('.')

import config

def analyze_system_resources():
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë¶„ì„"""
    print("ğŸ” ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë¶„ì„")
    print("=" * 50)
    
    # CPU ì •ë³´
    cpu_count = psutil.cpu_count(logical=False)  # ë¬¼ë¦¬ì  ì½”ì–´
    cpu_threads = psutil.cpu_count(logical=True)  # ë…¼ë¦¬ì  ì½”ì–´ (í•˜ì´í¼ìŠ¤ë ˆë”© í¬í•¨)
    cpu_freq = psutil.cpu_freq()
    
    print(f"ğŸ’» CPU ì •ë³´:")
    print(f"  - ë¬¼ë¦¬ì  ì½”ì–´: {cpu_count}ê°œ")
    print(f"  - ë…¼ë¦¬ì  ì½”ì–´: {cpu_threads}ê°œ (í•˜ì´í¼ìŠ¤ë ˆë”© í¬í•¨)")
    print(f"  - ê¸°ë³¸ ì£¼íŒŒìˆ˜: {cpu_freq.current:.0f} MHz")
    print(f"  - ìµœëŒ€ ì£¼íŒŒìˆ˜: {cpu_freq.max:.0f} MHz")
    
    # ë©”ëª¨ë¦¬ ì •ë³´
    memory = psutil.virtual_memory()
    print(f"\nğŸ’¾ ë©”ëª¨ë¦¬ ì •ë³´:")
    print(f"  - ì´ ë©”ëª¨ë¦¬: {memory.total / (1024**3):.1f} GB")
    print(f"  - ì‚¬ìš© ê°€ëŠ¥: {memory.available / (1024**3):.1f} GB")
    print(f"  - ì‚¬ìš©ë¥ : {memory.percent:.1f}%")
    
    # í˜„ì¬ CPU ì‚¬ìš©ë¥ 
    cpu_usage = psutil.cpu_percent(interval=1, percpu=True)
    avg_cpu = sum(cpu_usage) / len(cpu_usage)
    print(f"\nâš¡ í˜„ì¬ CPU ì‚¬ìš©ë¥ :")
    print(f"  - í‰ê· : {avg_cpu:.1f}%")
    print(f"  - ì½”ì–´ë³„: {[f'{usage:.1f}%' for usage in cpu_usage]}")
    
    # ê¶Œì¥ ì›Œì»¤ ìˆ˜ ê³„ì‚°
    recommended_workers = {
        "conservative": cpu_count,  # ë¬¼ë¦¬ì  ì½”ì–´ ìˆ˜
        "balanced": cpu_threads,    # ë…¼ë¦¬ì  ì½”ì–´ ìˆ˜
        "aggressive": cpu_threads + 2  # ë…¼ë¦¬ì  ì½”ì–´ + 2
    }
    
    print(f"\nğŸ”§ ê¶Œì¥ ì›Œì»¤ ìˆ˜:")
    print(f"  - ë³´ìˆ˜ì : {recommended_workers['conservative']}ê°œ (ë¬¼ë¦¬ì  ì½”ì–´)")
    print(f"  - ê· í˜•ì : {recommended_workers['balanced']}ê°œ (ë…¼ë¦¬ì  ì½”ì–´)")
    print(f"  - ì ê·¹ì : {recommended_workers['aggressive']}ê°œ (ë…¼ë¦¬ì  ì½”ì–´ + 2)")
    print(f"  - í˜„ì¬ ì„¤ì •: {config.MAX_WORKERS}ê°œ")
    
    return recommended_workers

def test_ollama_concurrent_capacity():
    """Ollama ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ§ª Ollama ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ì´ë¯¸ì§€ (DICOM ì²« ë²ˆì§¸ í˜ì´ì§€)
    test_image = Path("staging/DICOM/page_001.jpeg")
    if not test_image.exists():
        print("âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ–¼ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {test_image.name}")
    
    # ë‹¤ì–‘í•œ ë™ì‹œ ìš”ì²­ ìˆ˜ë¡œ í…ŒìŠ¤íŠ¸
    concurrent_levels = [1, 2, 4, 6, 8, 10, 12]
    results = {}
    
    for concurrent in concurrent_levels:
        print(f"\nğŸ”§ ë™ì‹œ ìš”ì²­ ìˆ˜: {concurrent}ê°œ")
        
        # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
        simple_prompt = "Describe this image briefly in one sentence."
        
        start_time = time.time()
        success_count = 0
        error_count = 0
        
        def single_request():
            try:
                # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
                import base64
                with open(test_image, "rb") as f:
                    image_base64 = base64.b64encode(f.read()).decode('utf-8')
                
                payload = {
                    "model": config.OLLAMA_MODEL,
                    "prompt": simple_prompt,
                    "images": [image_base64],
                    "stream": False
                }
                
                response = requests.post(
                    f"{config.OLLAMA_BASE_URL}/api/generate",
                    json=payload,
                    timeout=60
                )
                
                if response.status_code == 200:
                    return True
                else:
                    return False
                    
            except Exception as e:
                print(f"    âŒ ìš”ì²­ ì˜¤ë¥˜: {str(e)}")
                return False
        
        # ë³‘ë ¬ ìš”ì²­ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=concurrent) as executor:
            futures = [executor.submit(single_request) for _ in range(concurrent)]
            
            for future in as_completed(futures):
                if future.result():
                    success_count += 1
                else:
                    error_count += 1
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # ê²°ê³¼ ì €ì¥
        results[concurrent] = {
            "total_time": total_time,
            "success_count": success_count,
            "error_count": error_count,
            "throughput": success_count / total_time if total_time > 0 else 0
        }
        
        print(f"  â±ï¸ ì‹œê°„: {total_time:.2f}ì´ˆ")
        print(f"  âœ… ì„±ê³µ: {success_count}/{concurrent}")
        print(f"  âŒ ì‹¤íŒ¨: {error_count}/{concurrent}")
        print(f"  ğŸ“Š ì²˜ë¦¬ëŸ‰: {results[concurrent]['throughput']:.2f} req/sec")
        
        # ì‹¤íŒ¨ìœ¨ì´ ë†’ìœ¼ë©´ ì¤‘ë‹¨
        if error_count / concurrent > 0.5:
            print(f"  âš ï¸ ì‹¤íŒ¨ìœ¨ {error_count/concurrent*100:.1f}% - í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨")
            break
        
        # ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ì „ ì ì‹œ ëŒ€ê¸°
        time.sleep(2)
    
    # ê²°ê³¼ ë¶„ì„
    print(f"\nğŸ“Š Ollama ì²˜ë¦¬ ëŠ¥ë ¥ ë¶„ì„:")
    print(f"{'ë™ì‹œ ìš”ì²­':<8} {'ì‹œê°„(ì´ˆ)':<8} {'ì„±ê³µë¥ ':<8} {'ì²˜ë¦¬ëŸ‰':<12} {'ê¶Œì¥ë„':<8}")
    print("-" * 50)
    
    best_throughput = 0
    optimal_concurrent = 1
    
    for concurrent, result in results.items():
        success_rate = result['success_count'] / concurrent * 100
        throughput = result['throughput']
        
        if success_rate >= 90 and throughput > best_throughput:
            best_throughput = throughput
            optimal_concurrent = concurrent
            recommendation = "âœ… ìµœì "
        elif success_rate >= 80:
            recommendation = "ğŸŸ¡ ì–‘í˜¸"
        else:
            recommendation = "âŒ ê³¼ë¶€í•˜"
        
        print(f"{concurrent:<8} {result['total_time']:<8.2f} {success_rate:<8.1f}% {throughput:<12.2f} {recommendation}")
    
    print(f"\nğŸ¯ ê¶Œì¥ ì„¤ì •:")
    print(f"  - ìµœì  ë™ì‹œ ìš”ì²­ ìˆ˜: {optimal_concurrent}ê°œ")
    print(f"  - ìµœëŒ€ ì²˜ë¦¬ëŸ‰: {best_throughput:.2f} req/sec")
    
    return optimal_concurrent

def recommend_optimal_settings():
    """ìµœì  ì„¤ì • ê¶Œì¥"""
    print(f"\nğŸ”§ ìµœì  ì„¤ì • ê¶Œì¥")
    print("=" * 50)
    
    # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë¶„ì„
    cpu_threads = psutil.cpu_count(logical=True)
    memory_gb = psutil.virtual_memory().total / (1024**3)
    
    # Ollama ì²˜ë¦¬ ëŠ¥ë ¥ ê¸°ë°˜ ê¶Œì¥
    print(f"ğŸ“‹ í˜„ì¬ ì„¤ì •:")
    print(f"  - MAX_CONCURRENT_REQUESTS: {config.MAX_CONCURRENT_REQUESTS}")
    print(f"  - MAX_WORKERS: {config.MAX_WORKERS}")
    print(f"  - CHUNK_SIZE: {config.CHUNK_SIZE}")
    
    # ê¶Œì¥ ì„¤ì • ê³„ì‚°
    recommended_concurrent = min(6, cpu_threads // 2)  # CPU ë¶€í•˜ ê³ ë ¤
    recommended_workers = cpu_threads  # ë…¼ë¦¬ì  ì½”ì–´ ìˆ˜
    recommended_chunk = max(3, recommended_concurrent)  # ë™ì‹œ ìš”ì²­ ìˆ˜ì™€ ë¹„ìŠ·í•˜ê²Œ
    
    print(f"\nğŸ’¡ ê¶Œì¥ ì„¤ì •:")
    print(f"  - MAX_CONCURRENT_REQUESTS: {recommended_concurrent}ê°œ")
    print(f"  - MAX_WORKERS: {recommended_workers}ê°œ")
    print(f"  - CHUNK_SIZE: {recommended_chunk}ê°œ")
    
    # ì„¤ì • ë³€ê²½ ì½”ë“œ ìƒì„±
    config_code = f"""
# ì‹œìŠ¤í…œ ìµœì í™”ëœ ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
ENABLE_PARALLEL_PROCESSING = True
MAX_CONCURRENT_REQUESTS = {recommended_concurrent}  # CPU ê¸°ë°˜ ìµœì í™”
MAX_WORKERS = {recommended_workers}  # ë…¼ë¦¬ì  ì½”ì–´ ìˆ˜
CHUNK_SIZE = {recommended_chunk}  # ë©”ëª¨ë¦¬ ìµœì í™”
REQUEST_TIMEOUT = 180
RETRY_DELAY = 1
"""
    
    print(f"\nğŸ“ config.py ê¶Œì¥ ì„¤ì •:")
    print(config_code)
    
    return {
        "concurrent": recommended_concurrent,
        "workers": recommended_workers,
        "chunk_size": recommended_chunk
    }

if __name__ == "__main__":
    # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë¶„ì„
    system_info = analyze_system_resources()
    
    # Ollama ì²˜ë¦¬ ëŠ¥ë ¥ í…ŒìŠ¤íŠ¸
    optimal_concurrent = test_ollama_concurrent_capacity()
    
    # ìµœì  ì„¤ì • ê¶Œì¥
    optimal_settings = recommend_optimal_settings()
    
    print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ!")
    print(f"ì‹œìŠ¤í…œì— ìµœì í™”ëœ ì„¤ì •ì„ config.pyì— ì ìš©í•˜ì„¸ìš”.")