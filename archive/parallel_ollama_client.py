"""
Xinference APIë¥¼ ì‚¬ìš©í•˜ëŠ” Chunk ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬ í´ë¼ì´ì–¸íŠ¸
ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ chunk ë‹¨ìœ„ë¡œ ìˆœì°¨ ì²˜ë¦¬í•˜ë˜, chunk ë‚´ë¶€ëŠ” ë³‘ë ¬ ì²˜ë¦¬
"""

import asyncio
import aiohttp
import json
import base64
import time
from pathlib import Path
from typing import List, Optional, Dict, Tuple
import config

class ChunkedAsyncXinferenceClient:
    def __init__(self):
        self.base_url = config.XINFERENCE_BASE_URL
        self.model_name = config.XINFERENCE_MODEL_NAME
        self.model_uid = config.XINFERENCE_MODEL_UID
        self.max_concurrent = config.MAX_CONCURRENT_REQUESTS
        self.request_timeout = config.REQUEST_TIMEOUT
        self.retry_delay = config.RETRY_DELAY
        self.chunk_size = config.CHUNK_SIZE
        
        # ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œì„ ìœ„í•œ ì„¸ë§ˆí¬ì–´
        self.semaphore = asyncio.Semaphore(self.max_concurrent)
        self.stats_lock = asyncio.Lock()
        self.stats = {}
        
        self.reset_stats()

    def reset_stats(self):
        """í†µê³„ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”"""
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'total_time': 0,
            'concurrent_requests': 0
        }

    def encode_image_to_base64(self, image_path: Path) -> str:
        """ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    async def check_xinference_connection(self) -> bool:
        """Xinference ì„œë²„ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/v1/models", timeout=aiohttp.ClientTimeout(total=5)) as response:
                    return response.status == 200
        except Exception as e:
            print(f"âŒ Xinference ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    async def check_model_availability(self) -> bool:
        """ì§€ì •ëœ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ê³  model_uid ì„¤ì •"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/v1/models") as response:
                    if response.status == 200:
                        data = await response.json()
                        models = data.get('data', [])
                        for model in models:
                            if model.get('id', '').startswith(self.model_name):
                                self.model_uid = model.get('id')
                                return True
                    return False
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False

    def get_syncfusion_prompt(self) -> str:
        """Syncfusion SDK ë§¤ë‰´ì–¼ì— íŠ¹í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return """Convert this Syncfusion SDK documentation image to structured markdown format optimized for LLM fine-tuning and RAG applications.

CRITICAL REQUIREMENTS:

## Code Processing
- Extract ALL code snippets with proper language identification
- Preserve exact syntax, indentation, and formatting
- Use appropriate code blocks with language tags (```csharp, ```vb, ```xml, etc.)
- Maintain complete method signatures, parameter lists, and return types
- Include inline code elements using backticks for class names, properties, methods

## API Documentation Structure
- Identify and properly format: Classes, Namespaces, Methods, Properties, Events, Enums
- Use consistent heading hierarchy (# for main topics, ## for classes, ### for methods)
- Create clear parameter tables with: Name | Type | Description | Default Value
- Document return values with type and description
- Extract exception information if present

## Technical Content Enhancement
- Preserve all technical terminology exactly as written
- Maintain version-specific information and compatibility notes
- Include performance considerations and best practices
- Extract configuration settings and their valid values
- Document dependencies and required assemblies

## Structured Output Format
- Use descriptive headers that include class/namespace context
- Create linkable anchors for cross-references
- Format examples with clear "Example:" or "Usage:" headers
- Include "See Also" sections for related APIs
- Add metadata comments for categorization

## Content Completeness
- Extract ALL visible text without omission
- Preserve table structures with proper markdown formatting
- Maintain numbered/bulleted lists with correct nesting
- Include notes, warnings, and tips in appropriate callout format
- Capture image captions and figure references

## RAG Optimization
- Use semantic section breaks for better chunking
- Include contextual keywords for improved searchability
- Maintain hierarchical relationships between parent/child concepts
- Add implicit context where beneficial for standalone understanding

Focus on creating documentation that serves as high-quality training data for LLM fine-tuning while being immediately useful for RAG retrieval systems."""

    async def convert_single_image(self, session: aiohttp.ClientSession, image_path: Path, page_num: int) -> Tuple[int, Optional[str]]:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ (Xinference API ì‚¬ìš©)
        """
        async with self.semaphore:
            async with self.stats_lock:
                self.stats['total_requests'] += 1
                self.stats['concurrent_requests'] += 1
            
            start_time = time.time()
            
            try:
                image_base64 = self.encode_image_to_base64(image_path)
                
                # Xinference OpenAI í˜¸í™˜ API ì‚¬ìš©
                payload = {
                    "model": self.model_uid or self.model_name,
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": self.get_syncfusion_prompt()
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/jpeg;base64,{image_base64}"
                                    }
                                }
                            ]
                        }
                    ],
                    "max_tokens": 4000,
                    "stream": False
                }
                
                max_retries = 3
                last_exception = None
                
                for attempt in range(max_retries):
                    try:
                        timeout = aiohttp.ClientTimeout(total=self.request_timeout)
                        
                        async with session.post(
                            f"{self.base_url}/v1/chat/completions",
                            json=payload,
                            timeout=timeout,
                            headers={"Content-Type": "application/json"}
                        ) as response:
                            
                            if response.status == 200:
                                result = await response.json()
                                markdown_text = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                                
                                if markdown_text.strip():  # ë¹ˆ ë‚´ìš© ê²€ì‚¬
                                    async with self.stats_lock:
                                        self.stats['successful_requests'] += 1
                                        self.stats['total_time'] += time.time() - start_time
                                    return page_num, markdown_text
                                else:
                                    last_exception = "Empty response received"
                            else:
                                response_text = await response.text()
                                error_msg = f"HTTP {response.status}: {response_text[:200]}"
                                last_exception = error_msg
                                
                    except asyncio.TimeoutError as e:
                        error_msg = f"Timeout after {self.request_timeout}s"
                        last_exception = error_msg
                    except aiohttp.ClientError as e:
                        error_msg = f"Network error: {str(e)}"
                        last_exception = error_msg
                    except Exception as e:
                        error_msg = f"Unexpected error: {str(e)}"
                        last_exception = error_msg
                    
                    # ì¬ì‹œë„ ëŒ€ê¸° (ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹Œ ê²½ìš°)
                    if attempt < max_retries - 1:
                        wait_time = self.retry_delay * (attempt + 1)
                        await asyncio.sleep(wait_time)
                
                # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
                async with self.stats_lock:
                    self.stats['failed_requests'] += 1
                return page_num, None
                
            except Exception as e:
                async with self.stats_lock:
                    self.stats['failed_requests'] += 1
                return page_num, None
            finally:
                async with self.stats_lock:
                    self.stats['concurrent_requests'] -= 1

    async def process_chunk(self, chunk_idx: int, chunk_images: List[Path], total_chunks: int) -> Tuple[Dict[int, str], List[int]]:
        """ë‹¨ì¼ chunkë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
        chunk_results = {}
        chunk_failed = []
        chunk_start_time = time.time()
        
        print(f"\nğŸ“¦ Chunk {chunk_idx + 1}/{total_chunks} ì‹œì‘ ({len(chunk_images)}ê°œ í˜ì´ì§€)")
        
        # Chunk ë‚´ë¶€ì˜ ì§„í–‰ìƒí™© ì¶”ì 
        completed_in_chunk = 0
        progress_lock = asyncio.Lock()
        
        async def process_single_task(session: aiohttp.ClientSession, image_path: Path, page_num: int):
            nonlocal completed_in_chunk
            
            try:
                result = await self.convert_single_image(session, image_path, page_num)
                page_num_result, markdown_text = result
                
                async with progress_lock:
                    completed_in_chunk += 1
                    
                    if markdown_text and markdown_text.strip():
                        chunk_results[page_num_result] = markdown_text
                        print(f"âœ… [Chunk {chunk_idx + 1}] í˜ì´ì§€ {page_num_result} ì™„ë£Œ ({completed_in_chunk}/{len(chunk_images)}) - {len(markdown_text)} ë¬¸ì")
                    else:
                        chunk_results[page_num_result] = f"<!-- í˜ì´ì§€ {page_num_result} ë³€í™˜ ì‹¤íŒ¨: ë¹ˆ ì‘ë‹µ -->"
                        chunk_failed.append(page_num_result)
                        print(f"âŒ [Chunk {chunk_idx + 1}] í˜ì´ì§€ {page_num_result} ì‹¤íŒ¨ ({completed_in_chunk}/{len(chunk_images)}) - ë¹ˆ ì‘ë‹µ")
                        
            except Exception as e:
                async with progress_lock:
                    completed_in_chunk += 1
                    chunk_results[page_num] = f"<!-- í˜ì´ì§€ {page_num} ë³€í™˜ ì‹¤íŒ¨: {str(e)} -->"
                    chunk_failed.append(page_num)
                    print(f"âŒ [Chunk {chunk_idx + 1}] í˜ì´ì§€ {page_num} ì˜ˆì™¸: {str(e)} ({completed_in_chunk}/{len(chunk_images)})")
        
        # Chunk ë‚´ ëª¨ë“  ì‘ì—…ì„ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
        async with aiohttp.ClientSession() as session:
            tasks = [
                process_single_task(session, path, chunk_idx * self.chunk_size + i + 1)
                for i, path in enumerate(chunk_images)
            ]
            
            await asyncio.gather(*tasks, return_exceptions=True)
        
        chunk_time = time.time() - chunk_start_time
        success_count = len(chunk_results) - len(chunk_failed)
        print(f"ğŸ“¦ Chunk {chunk_idx + 1} ì™„ë£Œ: {success_count}/{len(chunk_images)} ì„±ê³µ, {chunk_time:.1f}ì´ˆ")
        
        return chunk_results, chunk_failed

    async def convert_images_to_markdown_parallel(self, image_paths: List[Path]) -> str:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ chunk ë‹¨ìœ„ ë°°ì¹˜ë¡œ ë¹„ë™ê¸° ë§ˆí¬ë‹¤ìš´ ë³€í™˜ (ë©”ëª¨ë¦¬ ìµœì í™”)
        """
        self.reset_stats()
        total_pages = len(image_paths)
        total_chunks = (total_pages + self.chunk_size - 1) // self.chunk_size
        
        print(f"ğŸš€ Chunk ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {total_pages}ê°œ í˜ì´ì§€")
        print(f"ğŸ“¦ Chunk ì„¤ì •: {self.chunk_size}ê°œì”© {total_chunks}ê°œ ë°°ì¹˜, ë°°ì¹˜ë‹¹ ìµœëŒ€ {self.max_concurrent}ê°œ ë™ì‹œ ì²˜ë¦¬")
        
        results = {}
        failed_pages = []
        start_time = time.time()
        overall_completed = 0
        
        # ì´ë¯¸ì§€ë¥¼ chunk ë‹¨ìœ„ë¡œ ë¶„í• 
        chunks = []
        for i in range(0, total_pages, self.chunk_size):
            chunk = image_paths[i:i + self.chunk_size]
            chunks.append(chunk)
            
        print(f"ğŸ“‹ Chunk ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ ë°°ì¹˜")
        
        # ê° chunkë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´)
        for chunk_idx, chunk_images in enumerate(chunks):
            chunk_results, chunk_failed = await self.process_chunk(chunk_idx, chunk_images, total_chunks)
            
            # ê²°ê³¼ë¥¼ ì „ì²´ ê²°ê³¼ì— ë³‘í•©
            results.update(chunk_results)
            failed_pages.extend(chunk_failed)
            overall_completed += len(chunk_images)
            
            # ì „ì²´ ì§„í–‰ìƒí™© ì¶œë ¥
            elapsed_time = time.time() - start_time
            progress_percent = (overall_completed / total_pages) * 100
            remaining_chunks = total_chunks - (chunk_idx + 1)
            estimated_remaining_time = (elapsed_time / (chunk_idx + 1)) * remaining_chunks if chunk_idx > 0 else 0
            
            print(f"\nğŸ¯ ì „ì²´ ì§„í–‰ìƒí™©: {overall_completed}/{total_pages} ({progress_percent:.1f}%)")
            print(f"â±ï¸ ê²½ê³¼ì‹œê°„: {elapsed_time/60:.1f}ë¶„, ë‚¨ì€ Chunk: {remaining_chunks}ê°œ")
            if remaining_chunks > 0:
                print(f"ğŸ“ˆ ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining_time/60:.1f}ë¶„")
            
            # Chunk ê°„ ì§§ì€ íœ´ì‹ (ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œê°„)
            if chunk_idx < total_chunks - 1:
                print(f"â¸ï¸ ë‹¤ìŒ Chunk ì¤€ë¹„ ì¤‘... (1ì´ˆ ëŒ€ê¸°)")
                await asyncio.sleep(1)

        print(f"\nğŸ‰ ëª¨ë“  Chunk ì²˜ë¦¬ ì™„ë£Œ!")
        
        # ê²°ê³¼ë¥¼ í˜ì´ì§€ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ ìƒì„±
        markdown_content = []
        for page_num in sorted(results.keys()):
            if page_num > 1:
                markdown_content.append("\n---\n")
            markdown_content.append(f"<!-- í˜ì´ì§€ {page_num} -->\n")
            markdown_content.append(results[page_num])
        
        total_time = time.time() - start_time
        
        print(f"\nğŸ“Š Chunk ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"  â±ï¸ ì´ ì‹œê°„: {total_time:.2f}ì´ˆ ({total_time/60:.1f}ë¶„)")
        print(f"  ğŸ“¦ ì²˜ë¦¬ëœ Chunk: {total_chunks}ê°œ ë°°ì¹˜")
        print(f"  ğŸ“ˆ ì²˜ë¦¬ëŸ‰: {len(image_paths) / total_time:.2f} í˜ì´ì§€/ì´ˆ")
        print(f"  âœ… ì„±ê³µ: {self.stats['successful_requests']}/{self.stats['total_requests']}")
        print(f"  âŒ ì‹¤íŒ¨: {self.stats['failed_requests']}/{self.stats['total_requests']}")
        if self.stats['successful_requests'] > 0:
            avg_time = self.stats['total_time'] / self.stats['successful_requests']
            print(f"  âš¡ í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            print(f"  ğŸ“¦ Chunkë‹¹ í‰ê·  ì‹œê°„: {total_time/total_chunks:.1f}ì´ˆ")
        if failed_pages:
            print(f"  âš ï¸ ì‹¤íŒ¨í•œ í˜ì´ì§€: {sorted(failed_pages)}")
        
        # ìµœì¢… í†µê³„
        print(f"\nğŸ—ï¸ Xinference ì„œë²„ ì„±ëŠ¥ ìš”ì•½:")
        if self.stats['successful_requests'] > 0:
            avg_response_time = self.stats['total_time'] / self.stats['successful_requests']
            print(f"  {self.base_url}: {self.stats['successful_requests']}ê°œ ì„±ê³µ, í‰ê·  {avg_response_time:.1f}ì´ˆ")
            print(f"  Chunk ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ìµœì í™” ì™„ë£Œ")
        
        return "\n".join(markdown_content)
    
    def post_process_syncfusion_content(self, markdown_content: str, pdf_name: str) -> str:
        """Syncfusion SDK ë§¤ë‰´ì–¼ ì½˜í…ì¸  í›„ì²˜ë¦¬"""
        if not config.SYNCFUSION_MODE:
            return markdown_content
            
        processed_content = []
        
        if config.INCLUDE_METADATA:
            metadata = f"""
---
title: "{pdf_name} - Syncfusion SDK Documentation"
type: "api-documentation"
framework: "syncfusion"
version: "v11"
extracted_date: "{time.time()}"
optimized_for: ["llm-training", "rag-retrieval"]
chunk_batch_processed: true
processing_stats:
  total_requests: {self.stats['total_requests']}
  successful_requests: {self.stats['successful_requests']}
  failed_requests: {self.stats['failed_requests']}
  chunk_size: {self.chunk_size}
---

"""
            processed_content.append(metadata)
        
        processed_content.append(markdown_content)
        return '\n'.join(processed_content)

# í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
AsyncXinferenceClient = ChunkedAsyncXinferenceClient
ParallelOllamaClient = ChunkedAsyncXinferenceClient
AsyncParallelOllamaClient = ChunkedAsyncXinferenceClient

async def main():
    """ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    client = ChunkedAsyncXinferenceClient()
    
    if await client.check_xinference_connection():
        print("âœ… Xinference ì„œë²„ ì—°ê²° ì„±ê³µ")
        
        if await client.check_model_availability():
            print(f"âœ… ëª¨ë¸ '{client.model_name}' ì‚¬ìš© ê°€ëŠ¥ (UID: {client.model_uid})")
            print(f"ğŸ”§ Chunk ë°°ì¹˜ ì„¤ì •: í¬ê¸° {client.chunk_size}, ìµœëŒ€ {client.max_concurrent}ê°œ ë™ì‹œ ìš”ì²­")
        else:
            print(f"âŒ ëª¨ë¸ '{client.model_name}' ì‚¬ìš© ë¶ˆê°€ëŠ¥")
    else:
        print("âŒ Xinference ì„œë²„ ì—°ê²° ì‹¤íŒ¨")

if __name__ == "__main__":
    asyncio.run(main())