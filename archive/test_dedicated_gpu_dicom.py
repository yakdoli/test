"""
GPU ì „ìš© ì›Œì»¤ë¡œ DICOM ë³€í™˜ í…ŒìŠ¤íŠ¸
GPUê°„ ì˜¤í”„ë¡œë“œ ì˜¤ë²„í—¤ë“œ ìµœì†Œí™” ê²€ì¦
"""

import asyncio
import time
from pathlib import Path
import config
from qwen_dedicated_gpu_client import DedicatedGPUQwenClient
from modules.core.checkpoint_manager import CheckpointManager
from modules.models.task_models import PDFTask, TaskStatus
from git_automation import GitAutomation

async def test_dedicated_gpu_dicom_conversion():
    print("ğŸš€ GPU ì „ìš© DICOM ë³€í™˜ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # GPU ì „ìš© í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    client = DedicatedGPUQwenClient()
    checkpoint_manager = CheckpointManager()
    git_automation = GitAutomation()
    
    # DICOM ì´ë¯¸ì§€ í™•ì¸
    dicom_staging = config.STAGING_DIR / "DICOM"
    image_files = sorted(list(dicom_staging.glob("*.jpeg")))
    
    if not image_files:
        print("âŒ DICOM ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € PDF ë³€í™˜ì„ ì‹¤í–‰í•˜ì„¸ìš”: python pdf_converter.py")
        return False
    
    print(f"ğŸ“‹ DICOM ì´ë¯¸ì§€ {len(image_files)}ê°œ ë°œê²¬")
    
    # GPU ì „ìš© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    print("\nğŸ§  GPU ì „ìš© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    start_init = time.time()
    
    if not await client.initialize_dedicated_system():
        print("âŒ GPU ì „ìš© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
        return False
    
    init_time = time.time() - start_init
    print(f"âœ… GPU ì „ìš© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ ({init_time:.1f}ì´ˆ)")
    
    # ì‹œìŠ¤í…œ ì„¤ì • ì •ë³´ ì¶œë ¥
    stats = client.get_dedicated_gpu_stats()
    print(f"\nğŸ“Š GPU ì „ìš© ì‹œìŠ¤í…œ ì„¤ì •:")
    print(f"   ëª¨ë“œ: {stats['mode']}")
    print(f"   GPU ìˆ˜: {stats['gpu_count']}ê°œ")
    print(f"   ì›Œì»¤ íƒ€ì…: {stats['worker_type']}")
    print(f"   ì˜¤í”„ë¡œë“œ ì˜¤ë²„í—¤ë“œ: {stats['offload_overhead']}")
    print(f"   GPUë³„ ì²˜ë¦¬: ê° GPUê°€ ì „ìš©ìœ¼ë¡œ ì²˜ë¦¬")
    
    # ì„¸ì…˜ ë° ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
    task = PDFTask(
        pdf_path=config.PDF_DIR / "DICOM.pdf",
        output_path=config.OUTPUT_DIR / "DICOM_dedicated_gpu_optimized.md"
    )
    
    session_id = checkpoint_manager.create_new_session([task])
    print(f"\nğŸ†” ë³€í™˜ ì„¸ì…˜: {session_id}")
    
    # GPU ì „ìš©ì„ ìœ„í•œ ì²­í¬ ì„¤ì • (GPUë³„ ë¶„ì‚°)
    gpu_count = stats['gpu_count']
    images_per_gpu = len(image_files) // gpu_count
    chunk_ids = checkpoint_manager.create_chunk_states("DICOM", len(image_files), images_per_gpu)
    print(f"ğŸ“¦ {len(chunk_ids)}ê°œ ì²­í¬ ìƒì„± (GPUë³„ ì „ìš© ì²˜ë¦¬, í‰ê·  {images_per_gpu}í˜ì´ì§€/GPU)")
    
    # ì‹¤ì œ GPU ì „ìš© ë³€í™˜ ì‹œì‘
    print(f"\nğŸ”„ GPU ì „ìš© ë³€í™˜ ì‹œì‘ ({len(image_files)}í˜ì´ì§€)")
    print(f"ğŸ¯ ëª©í‘œ: GPUê°„ ì˜¤í”„ë¡œë“œ ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”")
    start_time = time.time()
    
    try:
        # ì „ì²´ ì‘ì—… ì‹œì‘
        checkpoint_manager.update_task_status("DICOM", TaskStatus.IN_PROGRESS)
        
        # GPU ì „ìš© ë³‘ë ¬ ë³€í™˜ ì‹¤í–‰
        markdown_content = await client.convert_images_dedicated_gpu(image_files)
        
        if not markdown_content.strip():
            print("âŒ GPU ì „ìš© ë³€í™˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return False
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = time.time() - start_time
        
        # Syncfusion í›„ì²˜ë¦¬
        if config.SYNCFUSION_MODE:
            print("ğŸ”§ Syncfusion SDK ë§¤ë‰´ì–¼ í›„ì²˜ë¦¬ ì¤‘...")
            markdown_content = f"# DICOM SDK Documentation - Dedicated GPU Optimized\n\n{markdown_content}"
        
        # ê²°ê³¼ ì €ì¥
        output_file = config.OUTPUT_DIR / "DICOM_dedicated_gpu_optimized.md"
        
        # GPU ì „ìš© ìµœì í™” í—¤ë” ì¶”ê°€
        dedicated_stats = client.get_dedicated_gpu_stats()
        perf_stats = dedicated_stats['performance_stats']
        
        enhanced_header = f"""# DICOM SDK Documentation - Dedicated GPU Optimization

**GPU ì „ìš© ì˜¤í”„ë¡œë“œ ìµœì†Œí™” ê²°ê³¼:**
- ì„¸ì…˜ ID: {session_id}
- ì²˜ë¦¬ ëª¨ë“œ: Dedicated Single-GPU Workers (No Inter-GPU Offload)
- GPU ìˆ˜: {dedicated_stats['gpu_count']}ê°œ A100-SXM4-80GB
- ì›Œì»¤ íƒ€ì…: {dedicated_stats['worker_type']}
- ì´ í˜ì´ì§€: {len(image_files)}
- ì²­í¬ ìˆ˜: {len(chunk_ids)}

**ì„±ëŠ¥ ì§€í‘œ:**
- ì´ˆê¸°í™” ì‹œê°„: {init_time:.1f}ì´ˆ
- ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ
- ì´ ì‹œê°„: {init_time + processing_time:.1f}ì´ˆ
- ì²˜ë¦¬ëŸ‰: {len(image_files) / processing_time:.2f} í˜ì´ì§€/ì´ˆ
- GPUë³„ í‰ê· : {len(image_files) / dedicated_stats['gpu_count'] / processing_time:.2f} í˜ì´ì§€/ì´ˆ

**ì˜¤í”„ë¡œë“œ ìµœì†Œí™” ìµœì í™”:**
âœ… ê° ì›Œì»¤ê°€ ë‹¨ì¼ GPU ì „ìš© ì‚¬ìš©
âœ… GPUê°„ ë°ì´í„° ì´ë™ ì™„ì „ ì°¨ë‹¨
âœ… í”„ë¡œì„¸ìŠ¤ë³„ ë…ë¦½ì  GPU í• ë‹¹
âœ… ë©”ëª¨ë¦¬ ì˜¤í”„ë¡œë“œ ì˜¤ë²„í—¤ë“œ ì œê±°
âœ… CUDA ì»¨í…ìŠ¤íŠ¸ ìµœì í™”

**GPU ë¦¬ì†ŒìŠ¤ í™œìš©:**
- ì´ì „: GPUê°„ ì˜¤í”„ë¡œë“œë¡œ ì¸í•œ ì˜¤ë²„í—¤ë“œ
- í˜„ì¬: ê° GPU ë…ë¦½ì  ì „ìš© ì²˜ë¦¬
- GPUë³„ í• ë‹¹: í‰ê·  {len(image_files)/dedicated_stats['gpu_count']:.1f}ê°œ ì´ë¯¸ì§€
- ì˜¤í”„ë¡œë“œ ì˜¤ë²„í—¤ë“œ: {dedicated_stats['offload_overhead']}

---

{markdown_content}

---

**Enhanced by Claude Code with Dedicated GPU Optimization** ğŸš€ğŸ’¾ğŸ¤–
Generated on: {time.strftime('%Y-%m-%d %H:%M:%S')}
Processing Speed: {processing_time/len(image_files):.2f} seconds/page
GPU Architecture: {dedicated_stats['gpu_count']} Dedicated Workers
Offload Overhead: Minimized (No Inter-GPU Transfer)
"""
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(enhanced_header)
        
        # ëª¨ë“  ì²­í¬ë¥¼ ì™„ë£Œë¡œ í‘œì‹œ
        images_per_chunk = len(image_files) // len(chunk_ids) if chunk_ids else len(image_files)
        for i, chunk_id in enumerate(chunk_ids):
            start_page = i * images_per_chunk + 1
            end_page = min((i + 1) * images_per_chunk, len(image_files))
            processed_pages = list(range(start_page, end_page + 1))
            
            checkpoint_manager.update_chunk_status(
                chunk_id, TaskStatus.COMPLETED, 
                processed_pages=processed_pages
            )
        
        # ì „ì²´ ì‘ì—… ì™„ë£Œ
        checkpoint_manager.update_task_status("DICOM", TaskStatus.COMPLETED)
        
        # ìµœì¢… ì„±ëŠ¥ í†µê³„ ì¶œë ¥
        final_dedicated_stats = client.get_dedicated_gpu_stats()
        final_perf_stats = final_dedicated_stats['performance_stats']
        
        print(f"\nâœ… GPU ì „ìš© ë³€í™˜ ì™„ë£Œ!")
        print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_file}")
        print(f"ğŸ“Š ì´ ë¬¸ì ìˆ˜: {len(markdown_content):,}")
        
        print(f"\nâ±ï¸ ì‹œê°„ ë¶„ì„:")
        print(f"   ì´ˆê¸°í™” ì‹œê°„: {init_time:.1f}ì´ˆ")
        print(f"   ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ ({processing_time/60:.1f}ë¶„)")
        print(f"   ì´ ì‹œê°„: {init_time + processing_time:.1f}ì´ˆ")
        
        print(f"\nğŸš€ ì„±ëŠ¥ ì§€í‘œ:")
        print(f"   ì²˜ë¦¬ëŸ‰: {len(image_files) / processing_time:.2f} í˜ì´ì§€/ì´ˆ")
        print(f"   GPUë³„ í‰ê· : {len(image_files) / final_dedicated_stats['gpu_count'] / processing_time:.2f} í˜ì´ì§€/ì´ˆ")
        print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {processing_time/len(image_files):.2f}ì´ˆ/í˜ì´ì§€")
        
        print(f"\nğŸ”§ GPU ì „ìš© ì‹œìŠ¤í…œ:")
        print(f"   GPU ìˆ˜: {final_dedicated_stats['gpu_count']}ê°œ")
        print(f"   ì›Œì»¤ íƒ€ì…: {final_dedicated_stats['worker_type']}")
        print(f"   ì˜¤í”„ë¡œë“œ ìƒíƒœ: {final_dedicated_stats['offload_overhead']}")
        
        # GPU í™œìš©ë¥  í†µê³„ ì¶œë ¥
        if 'gpu_utilization_stats' in final_perf_stats:
            gpu_stats = final_perf_stats['gpu_utilization_stats']
            print(f"\nğŸ’¾ GPU í™œìš©ë¥  í†µê³„:")
            print(f"   GPU ìˆ˜: {gpu_stats['gpu_count']}ê°œ")
            print(f"   ì´ ì²˜ë¦¬ëŸ‰: {gpu_stats['total_throughput']:.2f} í˜ì´ì§€/ì´ˆ")
            print(f"   GPUë³„ ì²˜ë¦¬ëŸ‰: {gpu_stats['throughput_per_gpu']:.2f} í˜ì´ì§€/ì´ˆ")
            print(f"   ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”: {gpu_stats['overhead_minimized']}")
        
        # ì„±ëŠ¥ ê°œì„  ë¹„êµ
        baseline_time_per_page = 23.4  # ì´ì „ ë‹¨ì¼ GPU ê²°ê³¼
        current_time_per_page = processing_time / len(image_files)
        improvement_factor = baseline_time_per_page / current_time_per_page
        
        print(f"\nğŸ“ˆ ì„±ëŠ¥ ê°œì„  ë¶„ì„:")
        print(f"   ê¸°ì¤€ì„  (ë‹¨ì¼): ~{baseline_time_per_page:.1f}ì´ˆ/í˜ì´ì§€")
        print(f"   GPU ì „ìš©: {current_time_per_page:.2f}ì´ˆ/í˜ì´ì§€")
        print(f"   ê°œì„ ìœ¨: {improvement_factor:.1f}x ë¹ ë¦„ ({((improvement_factor-1)*100):.0f}% í–¥ìƒ)")
        print(f"   ì˜¤í”„ë¡œë“œ ì ˆì•½: GPUê°„ ì „ì†¡ ì˜¤ë²„í—¤ë“œ ì œê±°ë¨")
        
        # ìµœì¢… ì§„í–‰ë¥  í™•ì¸
        final_progress = checkpoint_manager.get_chunk_progress_summary("DICOM")
        if final_progress:
            print(f"\nğŸ“¦ ìµœì¢… ì§„í–‰ë¥ :")
            print(f"   ì²­í¬ ì™„ë£Œë¥ : {final_progress['chunk_progress_percent']:.1f}%")
            print(f"   í˜ì´ì§€ ì™„ë£Œë¥ : {final_progress['page_progress_percent']:.1f}%")
            print(f"   ì²˜ë¦¬ëœ í˜ì´ì§€: {final_progress['processed_pages']}/{final_progress['total_pages']}")
        
        # Git ì»¤ë°‹
        try:
            git_success = git_automation.create_task_commit(
                "Complete Dedicated GPU DICOM Conversion",
                f"""DICOM.pdf GPU ì „ìš© ì˜¤í”„ë¡œë“œ ìµœì†Œí™” ì™„ë£Œ

Dedicated GPU ìµœì í™” ê²°ê³¼:
- GPU ìˆ˜: {final_dedicated_stats['gpu_count']}ê°œ A100-SXM4-80GB
- ì›Œì»¤ íƒ€ì…: {final_dedicated_stats['worker_type']}
- ì´ {len(image_files)}í˜ì´ì§€ ì™„ë£Œ
- ì´ˆê¸°í™” ì‹œê°„: {init_time:.1f}ì´ˆ
- ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ
- ì²˜ë¦¬ëŸ‰: {len(image_files) / processing_time:.2f} í˜ì´ì§€/ì´ˆ
- ê°œì„ ìœ¨: {improvement_factor:.1f}x ì„±ëŠ¥ í–¥ìƒ
- ì„¸ì…˜ ID: {session_id}

GPUê°„ ì˜¤í”„ë¡œë“œ ìµœì†Œí™” ì„±ê³¼:
âœ… ê° ì›Œì»¤ê°€ ë‹¨ì¼ GPU ì „ìš© ì‚¬ìš©
âœ… GPUê°„ ë°ì´í„° ì´ë™ ì™„ì „ ì°¨ë‹¨
âœ… í”„ë¡œì„¸ìŠ¤ë³„ ë…ë¦½ì  GPU í• ë‹¹
âœ… ë©”ëª¨ë¦¬ ì˜¤í”„ë¡œë“œ ì˜¤ë²„í—¤ë“œ ì œê±°
âœ… ì˜¤ë²„í—¤ë“œ ìƒíƒœ: {final_dedicated_stats['offload_overhead']}""",
                [str(output_file.relative_to(config.BASE_DIR))]
            )
            
            if git_success:
                print("âœ… Git ì»¤ë°‹ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ Git ì»¤ë°‹ ê±´ë„ˆë›°ê¸°: {e}")
        
        return True
        
    except Exception as e:
        print(f"âŒ GPU ì „ìš© ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        
        # ì‹¤íŒ¨ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
        checkpoint_manager.update_task_status("DICOM", TaskStatus.FAILED, str(e))
        return False
    
    finally:
        # GPU ì „ìš© ì‹œìŠ¤í…œ ì •ë¦¬
        client.cleanup()

async def main():
    success = await test_dedicated_gpu_dicom_conversion()
    if success:
        print("\nğŸ‰ GPU ì „ìš© DICOM ë³€í™˜ ì„±ê³µ!")
        print("ğŸš€ GPUê°„ ì˜¤í”„ë¡œë“œ ì˜¤ë²„í—¤ë“œ ìµœì†Œí™” ì™„ë£Œ!")
    else:
        print("\nâŒ GPU ì „ìš© DICOM ë³€í™˜ ì‹¤íŒ¨")

if __name__ == "__main__":
    asyncio.run(main())