"""
í†µí•© Ollama/Qwen í´ë¼ì´ì–¸íŠ¸
Xinferenceì™€ ì§ì ‘ Qwen2.5-VL ì‚¬ìš©ì„ ì„¤ì •ì— ë”°ë¼ ì„ íƒ
"""

import asyncio
from pathlib import Path
from typing import List, Optional, Dict, Any
import config

# ì¡°ê±´ë¶€ ì„í¬íŠ¸
if config.USE_DIRECT_QWEN:
    from qwen_direct_client import DirectQwenVLClient
else:
    from parallel_ollama_client import ChunkedAsyncXinferenceClient


class UnifiedVLClient:
    """í†µí•© ë¹„ì „-ì–¸ì–´ ëª¨ë¸ í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        self.use_direct_qwen = config.USE_DIRECT_QWEN
        
        if self.use_direct_qwen:
            print("ğŸ¯ Direct Qwen2.5-VL-7B-Instruct ëª¨ë“œ í™œì„±í™”")
            self.client = DirectQwenVLClient()
        else:
            print("ğŸŒ Xinference API ëª¨ë“œ í™œì„±í™”")
            self.client = ChunkedAsyncXinferenceClient()
        
        self.stats = {
            'mode': 'direct_qwen' if self.use_direct_qwen else 'xinference',
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'total_time': 0
        }
    
    async def initialize(self) -> bool:
        """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if self.use_direct_qwen:
            return await self.client.initialize_model()
        else:
            # Xinference í´ë¼ì´ì–¸íŠ¸ëŠ” ë³„ë„ ì´ˆê¸°í™”ê°€ í•„ìš”ì—†ìŒ
            return await self.client.check_xinference_connection()
    
    async def check_availability(self) -> bool:
        """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        if self.use_direct_qwen:
            return self.client.model is not None
        else:
            return await self.client.check_model_availability()
    
    async def convert_images_to_markdown_parallel(self, image_paths: List[Path]) -> str:
        """ì´ë¯¸ì§€ë“¤ì„ ë³‘ë ¬ë¡œ ë§ˆí¬ë‹¤ìš´ ë³€í™˜"""
        start_time = asyncio.get_event_loop().time()
        
        try:
            result = await self.client.convert_images_to_markdown_parallel(image_paths)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats['total_requests'] += len(image_paths)
            self.stats['total_time'] += asyncio.get_event_loop().time() - start_time
            
            if result and result.strip():
                self.stats['successful_requests'] += len(image_paths)
            else:
                self.stats['failed_requests'] += len(image_paths)
            
            return result
            
        except Exception as e:
            self.stats['failed_requests'] += len(image_paths)
            print(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return f"<!-- ë³€í™˜ ì‹¤íŒ¨: {str(e)} -->"
    
    def post_process_syncfusion_content(self, markdown_content: str, pdf_name: str) -> str:
        """Syncfusion ì½˜í…ì¸  í›„ì²˜ë¦¬ (ê¸°ì¡´ ë©”ì„œë“œ í˜¸í™˜ì„±)"""
        if hasattr(self.client, 'post_process_syncfusion_content'):
            return self.client.post_process_syncfusion_content(markdown_content, pdf_name)
        else:
            # ì§ì ‘ í›„ì²˜ë¦¬ êµ¬í˜„
            if not config.SYNCFUSION_MODE:
                return markdown_content
                
            processed_content = []
            
            if config.INCLUDE_METADATA:
                metadata = f"""---
title: "{pdf_name} - Syncfusion SDK Documentation"
type: "api-documentation"
framework: "syncfusion"
version: "v11"
extracted_date: "{asyncio.get_event_loop().time()}"
optimized_for: ["llm-training", "rag-retrieval"]
processing_mode: "{self.stats['mode']}"
processing_stats:
  total_requests: {self.stats['total_requests']}
  successful_requests: {self.stats['successful_requests']}
  failed_requests: {self.stats['failed_requests']}
---

"""
                processed_content.append(metadata)
            
            processed_content.append(markdown_content)
            return '\n'.join(processed_content)
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        stats = self.stats.copy()
        
        if self.use_direct_qwen and hasattr(self.client, 'stats'):
            # Direct Qwen í´ë¼ì´ì–¸íŠ¸ì˜ ìƒì„¸ í†µê³„ ë³‘í•©
            direct_stats = self.client.stats
            stats.update({
                'detailed_stats': direct_stats,
                'average_processing_time': (
                    direct_stats['total_processing_time'] / direct_stats['successful_requests']
                    if direct_stats['successful_requests'] > 0 else 0
                )
            })
        elif not self.use_direct_qwen and hasattr(self.client, 'stats'):
            # Xinference í´ë¼ì´ì–¸íŠ¸ì˜ ìƒì„¸ í†µê³„ ë³‘í•©
            xinference_stats = self.client.stats
            stats.update({
                'detailed_stats': xinference_stats,
                'chunk_size': self.client.chunk_size,
                'max_concurrent': self.client.max_concurrent
            })
        
        return stats
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.use_direct_qwen and hasattr(self.client, 'cleanup'):
            self.client.cleanup()
        
        print(f"ğŸ§¹ {self.stats['mode']} í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ ì™„ë£Œ")


# í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­ë“¤
AsyncXinferenceClient = UnifiedVLClient
ParallelOllamaClient = UnifiedVLClient
AsyncParallelOllamaClient = UnifiedVLClient


async def main():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print(f"ğŸ§ª í†µí•© í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ëª¨ë“œ: {'Direct Qwen' if config.USE_DIRECT_QWEN else 'Xinference'})")
    
    client = UnifiedVLClient()
    
    if await client.initialize():
        print("âœ… í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
        
        if await client.check_availability():
            print("âœ… ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
            
            # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
            stats = client.get_performance_stats()
            print(f"ğŸ“Š ëª¨ë“œ: {stats['mode']}")
            
        else:
            print("âŒ ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€")
    else:
        print("âŒ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
    
    client.cleanup()


if __name__ == "__main__":
    asyncio.run(main())