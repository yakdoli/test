"""
ë³‘ë ¬ ì²˜ë¦¬ ì—”ì§„ êµ¬í˜„
"""
import asyncio
import concurrent.futures
import multiprocessing as mp
import threading
from pathlib import Path
from typing import List, Dict, Optional, Callable, Any
from datetime import datetime, timedelta
import psutil
from tqdm import tqdm

from modules.models.task_models import PDFTask, PageTask, TaskResult, BatchResult, TaskStatus
import config


class ResourceMonitor:
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self, cpu_threshold: float = 80.0, memory_threshold: float = 85.0):
        self.cpu_threshold = cpu_threshold
        self.memory_threshold = memory_threshold
        self._monitoring = False
        self._stats = {
            'cpu_usage': [],
            'memory_usage': [],
            'disk_usage': []
        }
    
    def get_current_usage(self) -> Dict[str, float]:
        """í˜„ì¬ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ë°˜í™˜"""
        return {
            'cpu': psutil.cpu_percent(interval=1),
            'memory': psutil.virtual_memory().percent,
            'disk': psutil.disk_usage('/').percent
        }
    
    def should_throttle(self) -> bool:
        """ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì´ ì„ê³„ì¹˜ë¥¼ ì´ˆê³¼í–ˆëŠ”ì§€ í™•ì¸"""
        usage = self.get_current_usage()
        return (usage['cpu'] > self.cpu_threshold or 
                usage['memory'] > self.memory_threshold)
    
    def get_optimal_worker_count(self) -> int:
        """ìµœì  ì›Œì»¤ ìˆ˜ ê³„ì‚°"""
        cpu_count = mp.cpu_count()
        usage = self.get_current_usage()
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì— ë”°ë¥¸ ì¡°ì •
        if usage['memory'] > 70:
            return max(1, cpu_count // 2)
        elif usage['memory'] > 50:
            return max(2, int(cpu_count * 0.75))
        else:
            return cpu_count


class ParallelProcessor:
    """ë³‘ë ¬ ì²˜ë¦¬ ì—”ì§„"""
    
    def __init__(self, max_workers: Optional[int] = None):
        self.resource_monitor = ResourceMonitor()
        self.max_workers = max_workers or self.resource_monitor.get_optimal_worker_count()
        self._executor = None
        self._progress_callback: Optional[Callable] = None
        
    def set_progress_callback(self, callback: Callable[[str, float], None]):
        """ì§„í–‰ ìƒí™© ì½œë°± ì„¤ì •"""
        self._progress_callback = callback
    
    def _update_progress(self, task_id: str, progress: float):
        """ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸"""
        if self._progress_callback:
            self._progress_callback(task_id, progress)
    
    def process_pdf_batch(self, pdf_tasks: List[PDFTask], 
                         converter_func: Callable[[PDFTask], TaskResult]) -> BatchResult:
        """PDF ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬"""
        print(f"ğŸš€ {len(pdf_tasks)}ê°œ PDF ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (ì›Œì»¤: {self.max_workers}ê°œ)")
        
        start_time = datetime.now()
        results = []
        
        with concurrent.futures.ProcessPoolExecutor(max_workers=self.max_workers) as executor:
            self._executor = executor
            
            # ì‘ì—… ì œì¶œ
            future_to_task = {
                executor.submit(converter_func, task): task 
                for task in pdf_tasks
            }
            
            # ì§„í–‰ ìƒí™© ì¶”ì 
            with tqdm(total=len(pdf_tasks), desc="PDF ë³€í™˜") as pbar:
                for future in concurrent.futures.as_completed(future_to_task):
                    task = future_to_task[future]
                    
                    try:
                        result = future.result()
                        results.append(result)
                        
                        if result.success:
                            pbar.set_postfix({"ì„±ê³µ": f"{task.pdf_path.stem}"})
                        else:
                            pbar.set_postfix({"ì‹¤íŒ¨": f"{task.pdf_path.stem}"})
                            
                    except Exception as e:
                        error_result = TaskResult(
                            task_id=task.pdf_path.stem,
                            success=False,
                            error_message=str(e)
                        )
                        results.append(error_result)
                        pbar.set_postfix({"ì˜¤ë¥˜": f"{task.pdf_path.stem}"})
                    
                    pbar.update(1)
                    
                    # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ë° ì¡°ì •
                    if self.resource_monitor.should_throttle():
                        print("âš ï¸ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë¶€ì¡± - ì²˜ë¦¬ ì†ë„ ì¡°ì ˆ ì¤‘...")
                        threading.Event().wait(2)  # 2ì´ˆ ëŒ€ê¸°
        
        end_time = datetime.now()
        processing_time = end_time - start_time
        
        # ê²°ê³¼ ì§‘ê³„
        successful = sum(1 for r in results if r.success)
        failed = len(results) - successful
        
        return BatchResult(
            total_tasks=len(pdf_tasks),
            successful_tasks=successful,
            failed_tasks=failed,
            skipped_tasks=0,
            total_processing_time=processing_time,
            results=results
        )
    
    def process_pages_parallel(self, page_tasks: List[PageTask],
                             converter_func: Callable[[PageTask], TaskResult]) -> List[TaskResult]:
        """í˜ì´ì§€ ë‹¨ìœ„ ë³‘ë ¬ ì²˜ë¦¬"""
        print(f"ğŸ“„ {len(page_tasks)}ê°œ í˜ì´ì§€ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘")
        
        results = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_task = {
                executor.submit(converter_func, task): task 
                for task in page_tasks
            }
            
            with tqdm(total=len(page_tasks), desc="í˜ì´ì§€ ë³€í™˜") as pbar:
                for future in concurrent.futures.as_completed(future_to_task):
                    task = future_to_task[future]
                    
                    try:
                        result = future.result()
                        results.append(result)
                        
                        if result.success:
                            pbar.set_postfix({"í˜ì´ì§€": f"{task.page_number}"})
                        else:
                            pbar.set_postfix({"ì‹¤íŒ¨": f"{task.page_number}"})
                            
                    except Exception as e:
                        error_result = TaskResult(
                            task_id=task.task_id,
                            success=False,
                            error_message=str(e)
                        )
                        results.append(error_result)
                    
                    pbar.update(1)
        
        return results
    
    def shutdown(self):
        """ì²˜ë¦¬ê¸° ì¢…ë£Œ"""
        if self._executor:
            self._executor.shutdown(wait=True)


class TaskManager:
    """ì‘ì—… ê´€ë¦¬ì - ì „ì²´ ì›Œí¬í”Œë¡œìš° ì¡°ì •"""
    
    def __init__(self, parallel_processor: ParallelProcessor):
        self.parallel_processor = parallel_processor
        self.checkpoint_manager = None  # ë‚˜ì¤‘ì— êµ¬í˜„
        self.progress_tracker = None    # ë‚˜ì¤‘ì— êµ¬í˜„
    
    def create_pdf_tasks(self, pdf_paths: List[Path]) -> List[PDFTask]:
        """PDF ê²½ë¡œ ëª©ë¡ì—ì„œ ì‘ì—… ê°ì²´ ìƒì„±"""
        tasks = []
        
        for pdf_path in pdf_paths:
            output_path = config.OUTPUT_DIR / f"{pdf_path.stem}.md"
            
            task = PDFTask(
                pdf_path=pdf_path,
                output_path=output_path,
                priority=0  # ê¸°ë³¸ ìš°ì„ ìˆœìœ„
            )
            tasks.append(task)
        
        return tasks
    
    def estimate_processing_time(self, tasks: List[PDFTask]) -> timedelta:
        """ì²˜ë¦¬ ì‹œê°„ ì˜ˆìƒ"""
        # í˜ì´ì§€ë‹¹ í‰ê·  137ì´ˆ (common.pdf í…ŒìŠ¤íŠ¸ ê¸°ì¤€)
        avg_time_per_page = 137
        
        total_pages = 0
        for task in tasks:
            # PDF í˜ì´ì§€ ìˆ˜ ì¶”ì • (ì‹¤ì œë¡œëŠ” PDFë¥¼ ì—´ì–´ì„œ í™•ì¸í•´ì•¼ í•¨)
            # ì—¬ê¸°ì„œëŠ” íŒŒì¼ í¬ê¸° ê¸°ë°˜ ì¶”ì •
            file_size_mb = task.pdf_path.stat().st_size / (1024 * 1024)
            estimated_pages = max(1, int(file_size_mb * 25))  # ëŒ€ëµì  ì¶”ì •
            total_pages += estimated_pages
        
        total_seconds = total_pages * avg_time_per_page / self.parallel_processor.max_workers
        return timedelta(seconds=total_seconds)
    
    def run_batch_processing(self, pdf_paths: List[Path]) -> BatchResult:
        """ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰"""
        tasks = self.create_pdf_tasks(pdf_paths)
        
        # ì²˜ë¦¬ ì‹œê°„ ì˜ˆìƒ
        estimated_time = self.estimate_processing_time(tasks)
        print(f"â±ï¸ ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„: {estimated_time}")
        
        # ì‹¤ì œ ë³€í™˜ í•¨ìˆ˜ëŠ” ë‚˜ì¤‘ì— êµ¬í˜„
        def dummy_converter(task: PDFTask) -> TaskResult:
            """ì„ì‹œ ë³€í™˜ í•¨ìˆ˜ - ì‹¤ì œ êµ¬í˜„ í•„ìš”"""
            return TaskResult(
                task_id=task.pdf_path.stem,
                success=True,
                output_path=task.output_path,
                processing_time=timedelta(seconds=10)
            )
        
        return self.parallel_processor.process_pdf_batch(tasks, dummy_converter)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    processor = ParallelProcessor(max_workers=2)
    manager = TaskManager(processor)
    
    # í…ŒìŠ¤íŠ¸ìš© PDF ê²½ë¡œ
    test_pdfs = list(config.PDF_DIR.glob("*.pdf"))[:2]  # ì²˜ìŒ 2ê°œë§Œ í…ŒìŠ¤íŠ¸
    
    if test_pdfs:
        print("ğŸ§ª ë³‘ë ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        result = manager.run_batch_processing(test_pdfs)
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {result.success_rate:.1%} ì„±ê³µë¥ ")
    else:
        print("âŒ í…ŒìŠ¤íŠ¸í•  PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")