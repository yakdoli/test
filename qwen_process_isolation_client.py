"""
Qwen2.5-VL í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ë³‘ë ¬ ì²˜ë¦¬ í´ë¼ì´ì–¸íŠ¸ (Xinference + qwen-vl-utils)

- ê° ì›Œì»¤ëŠ” ë…ë¦½ í”„ë¡œì„¸ìŠ¤ë¡œ ê²©ë¦¬ë˜ì–´ Xinference OpenAI í˜¸í™˜ APIë¥¼ í˜¸ì¶œ
- qwen-vl-utilsë¥¼ í™œìš©í•´ ì…ë ¥ ë©”ì‹œì§€/ì´ë¯¸ì§€ ìœ íš¨ì„± í™•ì¸(ë¡œì»¬ ì „ì²˜ë¦¬)
- ë¡œì»¬ HF ëª¨ë¸ ë¡œë”© ì œê±° â†’ ê²½ëŸ‰/ì•ˆì •ì„± í–¥ìƒ, ì„œë²„(Xinference)ì—ì„œ ëª¨ë¸ ê´€ë¦¬
"""

import asyncio
import multiprocessing
import os
import pickle
import psutil
import time
from concurrent.futures import ProcessPoolExecutor
from pathlib import Path
from typing import List, Optional, Dict, Any, Tuple
from modules.utils.prompt_utils import build_syncfusion_prompt
from datetime import datetime

import config
from modules.utils.md_staging import save_page_markdown



def process_isolated_image_batch(args_tuple) -> List[str]:
    """í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ëœ ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬ (Xinference API í˜¸ì¶œ)"""
    from qwen_vl_utils import process_vision_info  # ìœ íš¨ì„± í™•ì¸ ìš©ë„
    import base64
    import requests

    def encode_image_to_base64(image_path: Path) -> str:
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")

    try:
        # ì¸ìˆ˜ íŠœí”Œ ë¶„í•´
        worker_id, batch_data = args_tuple

        # ë°°ì¹˜ ë°ì´í„° ì—­ì§ë ¬í™”
        image_paths: List[Path] = pickle.loads(batch_data)
        process_id = os.getpid()

        # Xinference ì—”ë“œí¬ì¸íŠ¸/ëª¨ë¸ ì •ë³´ (ì‚¬ì „ í•´ì„ëœ ëª¨ë¸ ID ìš°ì„ )
        base_url = os.environ.get("XINFERENCE_BASE_URL", getattr(config, "XINFERENCE_BASE_URL", "http://localhost:9997"))
        model = os.environ.get("XINFERENCE_RESOLVED_MODEL") or \
            getattr(config, "XINFERENCE_MODEL_UID", None) or \
            getattr(config, "XINFERENCE_MODEL_NAME", "qwen2.5-vl-instruct")

        print(f"ğŸ”§ í”„ë¡œì„¸ìŠ¤ {process_id} - ì›Œì»¤ {worker_id} ì´ˆê¸°í™” (Xinference API: {base_url})")

        results: List[str] = []
        process_start_time = time.time()

        session = requests.Session()
        timeout = getattr(config, "REQUEST_TIMEOUT", 300)
        max_retries = 3

        for idx, image_path in enumerate(image_paths):
            try:
                # qwen-vl-utilsë¡œ ë©”ì‹œì§€ ìŠ¤í‚¤ë§ˆ ê²€ì¦(ì´ë¯¸ì§€ ê²½ë¡œ ìœ íš¨ì„± ë“±)
                try:
                    messages_for_validation = [{
                        "role": "user",
                        "content": [
                            {"type": "image", "image": str(image_path)},
                            {"type": "text", "text": build_syncfusion_prompt(image_path)}
                        ]
                    }]
                    # ë°˜í™˜ê°’ì€ ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ, ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¡°ê¸° ê°ì§€ ëª©ì 
                    _ = process_vision_info(messages_for_validation)
                except Exception as ve:
                    print(f"   âš ï¸ ì…ë ¥ ìœ íš¨ì„± ê²½ê³ (ì›Œì»¤ {worker_id}): {image_path.name} - {ve}")

                # ì´ë¯¸ì§€ base64 ì¸ì½”ë”©
                image_b64 = encode_image_to_base64(image_path)

                # OpenAI í˜¸í™˜ Chat Completions í˜ì´ë¡œë“œ êµ¬ì„±
                payload = {
                    "model": model,
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": build_syncfusion_prompt(image_path)},
                                {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}}
                            ]
                        }
                    ],
                    "max_tokens": 4000,
                    "stream": False
                }

                last_error: Optional[str] = None
                for attempt in range(1, max_retries + 1):
                    try:
                        resp = session.post(
                            f"{base_url}/v1/chat/completions",
                            json=payload,
                            timeout=timeout,
                            headers={"Content-Type": "application/json"}
                        )
                        if resp.status_code == 200:
                            data = resp.json()
                            content = (
                                data.get("choices", [{}])[0]
                                .get("message", {})
                                .get("content", "")
                            )
                            if content and content.strip():
                                results.append(content)
                                print(
                                    f"   âœ… í”„ë¡œì„¸ìŠ¤ {process_id} - ì›Œì»¤ {worker_id}: "
                                    f"ì´ë¯¸ì§€ {idx+1}/{len(image_paths)} ì™„ë£Œ ({len(content)}ì)"
                                )
                                # í˜ì´ì§€ ë‹¨ìœ„ MD ìŠ¤í…Œì´ì§• ì €ì¥
                                try:
                                    save_page_markdown(
                                        image_path,
                                        content,
                                        mode="process_isolated",
                                        prompt=build_syncfusion_prompt(image_path),
                                        extra_meta={
                                            "client": "ProcessIsolatedQwenClient",
                                            "worker_id": worker_id,
                                            "process_id": process_id,
                                        },
                                    )
                                except Exception as _e:
                                    print(f"   âš ï¸ MD ìŠ¤í…Œì´ì§• ì €ì¥ ê²½ê³ : {str(_e)}")
                                break
                            else:
                                last_error = "Empty response"
                                print(
                                    f"   âš ï¸ ë¹ˆ ì‘ë‹µ(ì‹œë„ {attempt}/{max_retries}) - {image_path.name}"
                                )
                        else:
                            last_error = f"HTTP {resp.status_code}: {resp.text[:200]}"
                            print(
                                f"   âŒ API ì˜¤ë¥˜(ì‹œë„ {attempt}/{max_retries}) - {last_error}"
                            )
                    except requests.exceptions.Timeout:
                        last_error = f"Timeout after {timeout}s"
                        print(
                            f"   â° íƒ€ì„ì•„ì›ƒ(ì‹œë„ {attempt}/{max_retries}) - {image_path.name}: {last_error}"
                        )
                    except requests.RequestException as re:
                        last_error = f"Network error: {re}"
                        print(
                            f"   ğŸ”Œ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜(ì‹œë„ {attempt}/{max_retries}) - {image_path.name}: {last_error}"
                        )

                    if attempt < max_retries:
                        delay = getattr(config, "RETRY_DELAY", 2) * attempt
                        time.sleep(delay)
                else:
                    # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
                    fail_msg = f"<!-- í”„ë¡œì„¸ìŠ¤ {process_id} - ì›Œì»¤ {worker_id} ì²˜ë¦¬ ì‹¤íŒ¨: {image_path.name} - {last_error} -->"
                    results.append(fail_msg)
                    print(f"   âŒ ìµœì¢… ì‹¤íŒ¨ - {image_path.name}: {last_error}")

            except Exception as e:
                error_msg = f"<!-- í”„ë¡œì„¸ìŠ¤ {process_id} - ì›Œì»¤ {worker_id} ì²˜ë¦¬ ì‹¤íŒ¨: {image_path.name} - {str(e)} -->"
                results.append(error_msg)
                print(f"   âŒ ì˜ˆì™¸ - ì´ë¯¸ì§€ {idx+1}: {e}")

        process_time = time.time() - process_start_time
        throughput = len(image_paths) / process_time if process_time > 0 else 0

        print(
            f"ğŸ¯ í”„ë¡œì„¸ìŠ¤ {process_id} - ì›Œì»¤ {worker_id} ì™„ë£Œ: "
            f"{len(results)}ê°œ, {process_time:.1f}ì´ˆ, {throughput:.2f} ì´ë¯¸ì§€/ì´ˆ"
        )

        return results

    except Exception as e:
        print(f"âŒ í”„ë¡œì„¸ìŠ¤ ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜(ì›Œì»¤ {locals().get('worker_id', '?')}): {e}")
        return [f"<!-- í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹¤íŒ¨: {str(e)} -->"]


# NOTE: Deprecated local prompt function (replaced by modules.utils.prompt_utils.build_syncfusion_prompt)
# def get_syncfusion_prompt(image_path: Path) -> str:
    """Syncfusion íŠ¹í™” í”„ë¡¬í”„íŠ¸ (í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ìµœì í™”)
    - ë¯¸ì„¸ì¡°ì • ë°ì´í„°ì…‹/RAG ì¼ê´€ì„± ê°•í™”ë¥¼ ìœ„í•´ ë™ì  ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ì§€ì‹œë¬¸
    - ì»¨í…ìŠ¤íŠ¸/ë©”íƒ€ ì •ë³´ í‘œì¤€í™”, ì„¹ì…˜ ìŠ¤í‚¤ë§ˆ ê³ ì •, ì–¸ì–´/ì½”ë“œ/í‘œ/ë¦¬ìŠ¤íŠ¸/ë§í¬ ì²˜ë¦¬ ê·œì•½ ê°•í™”
    - OCR ì •ê·œí™” ê·œì¹™ í¬í•¨ (ë„ì–´ì“°ê¸°, í•˜ì´í”ˆ ì¤„ë°”ê¿ˆ, íŠ¹ìˆ˜ë¬¸ì í†µí•© ë“±)
    """
    import re
    from datetime import datetime

    # ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
    file_name = image_path.name
    parent_dir = image_path.parent.name
    stem = image_path.stem
    m = re.search(r"page[_-]?(\d+)", stem, re.IGNORECASE)
    page_number = m.group(1) if m else "unknown"

    # ISO-8601 UTC íƒ€ì„ìŠ¤íƒ¬í”„ (ì´ˆ ë‹¨ìœ„)
    iso_ts = datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

    # ëª¨ë¸ì— ì „ë‹¬í•  ì»¨í…ìŠ¤íŠ¸ + ì—„ê²©í•œ ì¶œë ¥ ê³„ì•½
    return f"""
You are a meticulous technical documentation OCR and structuring agent specialized in Syncfusion SDK manuals.
Your task is to convert the given documentation image into HIGH-FIDELITY Markdown that is suitable for LLM fine-tuning datasets and RAG retrieval.

CONTEXT VALUES (use EXACTLY in the metadata header):
- source: image
- domain: syncfusion-sdk
- task: pdf-ocr-to-markdown
- language: auto (keep original; do not translate)
- source_filename: {file_name}
- document_name: {parent_dir}
- page_number: {page_number}
- page_id: {parent_dir}#page_{page_number}
- timestamp: {iso_ts}
- fidelity: lossless

GLOBAL OUTPUT CONTRACT (MUST FOLLOW EXACTLY):
- Top-level must start with an HTML comment metadata block:
  <!--
  source: image
  domain: syncfusion-sdk
  task: pdf-ocr-to-markdown
  language: auto (keep original; do not translate)
  source_filename: {file_name}
  document_name: {parent_dir}
  page_number: {page_number}
  page_id: {parent_dir}#page_{page_number}
  timestamp: {iso_ts}
  fidelity: lossless
  -->
- After metadata, output the structured content only in Markdown. No extra explanations.
- Do not invent content. If text is cropped/unclear, include "[unclear]" and keep position.
- Preserve all text as-is except for OCR normalization rules below.

OCR NORMALIZATION RULES:
- Merge hyphenated line breaks: "inter-
  face" -> "interface" when it's the same token.
- Normalize multiple spaces to single spaces, but preserve indentation inside code blocks.
- Preserve Unicode punctuation and math symbols as-is.
- Keep list numbering as shown (don't renumber).
- Keep casing exactly; do not title-case or sentence-case.

STRUCTURE SCHEMA (ENFORCE):
# {{Page/Main Title}}

## Overview
- 1-3 bullets summarizing the page scope using only visible text.

## Content
- Reconstruct hierarchy (H2/H3/H4) exactly as in image.
- Tables: use GitHub-flavored Markdown. Keep column order, headers, alignment if visible.
- Lists: preserve nesting and markers (-, *, 1.) as-is.
- Callouts: map to blockquotes with labels (Note:, Warning:, Tip:).
- Figures/Captions: include as "Figure: ..." lines when present.

## API Reference (if applicable)
- Namespace, Class, Members (Methods/Properties/Events/Enums) in subsections.
- Parameters table: Name | Type | Description | Default | Required
- Returns: Type + description.
- Exceptions: bullet list.

## Code Examples (multi-language supported)
- Extract ALL code exactly. Use fenced blocks with language: ```csharp, ```vb, ```xml, ```xaml, ```js, ```css, ```ts, ```python.
- Keep full signatures, imports/usings, comments, region markers.
- Inline code in text should be wrapped with backticks.

## Cross References
- Add See also: bullet list of explicit links/texts present on the page. Do not fabricate.

## RAG Annotations
- At the end, add an HTML comment with tags and keywords derived ONLY from visible content:
  <!-- tags: [product, module, control, api, version?] keywords: [k1, k2, ...] -->

ADDITIONAL RULES:
- Units, versions, file paths, and identifiers must be preserved exactly.
- Do not reflow long lines inside code blocks.
- Preserve table cell line breaks using <br> if present.
- For cross-page references without URLs, keep the exact anchor text.

Output now in the specified format.
"""


class ProcessIsolationResourceManager:
    """í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì"""
    
    def __init__(self):
        import torch
        self.gpu_available = torch.cuda.is_available()
        self.device_count = torch.cuda.device_count() if self.gpu_available else 0
        self.cpu_count = multiprocessing.cpu_count()
        self.system_memory = psutil.virtual_memory()
        
    def get_optimal_process_config(self) -> Dict[str, Any]:
        """ìµœì  í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì„¤ì •
        - Xinference ì‚¬ìš© ì‹œ í´ë¼ì´ì–¸íŠ¸ í”„ë¡œì„¸ìŠ¤ëŠ” GPU ë¶ˆí•„ìš” â†’ CPU ê¸°ë°˜ ë³‘ë ¬í™”
        - ë¡œì»¬ ëª¨ë¸ ì‚¬ìš© ì „í™˜ ì‹œì—ëŠ” GPU ê°œìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì œí•œ
        """
        # ê¸°ë³¸ ê¶Œì¥ í”„ë¡œì„¸ìŠ¤ ìˆ˜ ê³„ì‚°
        cpu_based = max(1, min(self.cpu_count // 2, getattr(config, 'MAX_WORKERS', 8)))
        gpu_based = max(1, self.device_count) if self.gpu_available else 1

        # ëª¨ë“œì— ë”°ë¥¸ ê²°ì •
        if getattr(config, 'USE_DIRECT_QWEN', False):
            recommended_processes = min(gpu_based, cpu_based)
        else:
            # Xinference ëª¨ë“œ: CPU ê¸°ë°˜ ë™ì‹œì„± ì‚¬ìš© (I/O ë°”ìš´ë“œ HTTP)
            recommended_processes = cpu_based

        print(f"ğŸ”§ í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ë¦¬ì†ŒìŠ¤ ë¶„ì„:")
        print(f"   GPU ê°œìˆ˜: {self.device_count}")
        print(f"   CPU ì½”ì–´: {self.cpu_count}")
        print(f"   ì‹œìŠ¤í…œ RAM: {self.system_memory.total / (1024**3):.1f}GB")
        print(f"   ê¶Œì¥ í”„ë¡œì„¸ìŠ¤ ìˆ˜: {recommended_processes}")
        
        return {
            'max_processes': recommended_processes,
            'gpus_available': self.device_count,
            'isolation_mode': 'complete_process_isolation',
            'memory_isolation': True
        }


class ProcessIsolatedQwenClient:
    """í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ Qwen2.5-VL í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        # spawn ë°©ì‹ìœ¼ë¡œ ë©€í‹°í”„ë¡œì„¸ì‹± ì„¤ì • (CUDA í˜¸í™˜)
        multiprocessing.set_start_method('spawn', force=True)
        
        self.resource_manager = ProcessIsolationResourceManager()
        self.process_pool = None
        self.workers_initialized = False
        self.xinference_model_id: Optional[str] = None  
        self.stats = {
            'total_images': 0,
            'total_processing_time': 0,
            'process_stats': {},
            'isolation_overhead': 0
        }
        
    async def initialize_isolated_system(self) -> bool:
        """í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        print("ğŸš€ í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        
        try:
            config = self.resource_manager.get_optimal_process_config()
            max_processes = config['max_processes']
            
            # ProcessPoolExecutor ìƒì„± (spawn context)
            ctx = multiprocessing.get_context('spawn')
            self.process_pool = ProcessPoolExecutor(
                max_workers=max_processes,
                mp_context=ctx
            )
            
            print(f"âœ… í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {max_processes}ê°œ ë…ë¦½ í”„ë¡œì„¸ìŠ¤")
            self.workers_initialized = True
            return True
            
        except Exception as e:
            print(f"âŒ í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    async def convert_images_process_isolated(self, image_paths: List[Path]) -> str:
        """í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì´ë¯¸ì§€ ë³€í™˜ (Xinference API í˜¸ì¶œ ê¸°ë°˜)"""
        if not self.workers_initialized:
            if not await self.initialize_isolated_system():
                return "í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨"

        # ì‚¬ì „ í—¬ìŠ¤ì²´í¬ ë° ëª¨ë¸ ID í•´ì„
        try:
            import requests
            base_url = getattr(config, "XINFERENCE_BASE_URL", "http://localhost:9997")
            resp = requests.get(f"{base_url}/v1/models", timeout=10)
            if resp.status_code != 200:
                return f"<!-- Xinference í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: HTTP {resp.status_code} -->"
            data = resp.json()
            models = data.get('data', []) if isinstance(data, dict) else []
            name = getattr(config, 'XINFERENCE_MODEL_NAME', 'qwen2.5-vl-instruct')
            found = None
            for m in models:
                mid = m.get('id') or m.get('model')
                if not mid:
                    continue
                if mid.startswith(name):
                    found = mid
                    break
            if not found and getattr(config, 'XINFERENCE_MODEL_UID', None):
                found = getattr(config, 'XINFERENCE_MODEL_UID')
            if not found:
                print("âŒ Xinferenceì— ëŒ€ìƒ ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. start_xinference.sh ì‹¤í–‰ í›„ /v1/modelsì— ëª¨ë¸ì´ ë³´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
                return "<!-- Xinference ëª¨ë¸ ë¯¸ë¡œë”©: start_xinference.shë¡œ ëª¨ë¸ êµ¬ë™ í›„ ì¬ì‹œë„ -->"
            self.xinference_model_id = found
            # ì›Œì»¤ì— í™˜ê²½ë³€ìˆ˜ë¡œ ì „ë‹¬(ìŠ¤í° ì‹œ ìƒì†)
            os.environ['XINFERENCE_BASE_URL'] = base_url
            os.environ['XINFERENCE_RESOLVED_MODEL'] = self.xinference_model_id
            print(f"ğŸ”— Xinference ëª¨ë¸ í™•ì¸: {self.xinference_model_id}")
        except Exception as e:
            print(f"âš ï¸ Xinference ëª¨ë¸ í™•ì¸ ì¤‘ ì˜ˆì™¸: {e}")
            # ê³„ì† ì‹œë„í•˜ë˜, ì„œë²„ ì¸¡ì—ì„œ 500 ë°œìƒ ì‹œ ì¬ì‹œë„ ë¡œì§ì´ ì²˜ë¦¬
        
        total_images = len(image_paths)
        # ì›Œì»¤ ìˆ˜ ê¸°ì¤€ ê· ë“± ë¶„í•  (Xinference ëª¨ë“œì—ì„œëŠ” GPUì™€ ë¬´ê´€)
        max_workers = self.process_pool._max_workers if self.process_pool else 1
        safe_concurrency = getattr(config, 'MAX_CONCURRENT_REQUESTS', 6)
        num_batches = min(max_workers, total_images, safe_concurrency) if total_images > 0 else 0

        batches: List[Tuple[int, List[Path]]] = []
        for i in range(num_batches):
            batches.append((i, []))
        for idx, p in enumerate(image_paths):
            batches[idx % num_batches][1].append(p)

        print(f"ğŸš€ í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ë³€í™˜ ì‹œì‘:")
        print(f"   ì´ ì´ë¯¸ì§€: {total_images}ê°œ")
        print(f"   ë…ë¦½ í”„ë¡œì„¸ìŠ¤: {len(batches)}ê°œ")
        print(f"   ëª¨ë“œ: {'Xinference API' if not getattr(config, 'USE_DIRECT_QWEN', False) else 'Direct HF Model'}")
        if self.xinference_model_id:
            print(f"   ëŒ€ìƒ ëª¨ë¸ ID: {self.xinference_model_id}")
        
        start_time = datetime.now()
        
        # ê° ë°°ì¹˜ë¥¼ ë…ë¦½ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì²˜ë¦¬
        loop = asyncio.get_event_loop()
        tasks = []
        
        for worker_id, batch in batches:
            # ë°°ì¹˜ ë°ì´í„° ì§ë ¬í™”
            batch_data = pickle.dumps(batch)
            
            # ë…ë¦½ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (GPU IDì™€ ë°°ì¹˜ ë°ì´í„°ë¥¼ íŠœí”Œë¡œ ì „ë‹¬)
            task = loop.run_in_executor(
                self.process_pool,
                process_isolated_image_batch,
                (worker_id, batch_data)
            )
            tasks.append((task, worker_id, len(batch)))
        
        print(f"âš¡ {len(tasks)}ê°œ ì™„ì „ ê²©ë¦¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘...")
        
        # ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸°
        all_results = {}
        page_counter = 1
        
        for task, worker_id, batch_size in tasks:
            try:
                batch_results = await task
                
                for result in batch_results:
                    all_results[page_counter] = result
                    page_counter += 1
                
                print(f"âœ… í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì™„ë£Œ - ì›Œì»¤ {worker_id}: {batch_size}ê°œ ì²˜ë¦¬")
                
            except Exception as e:
                print(f"âŒ í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹¤íŒ¨ - ì›Œì»¤ {worker_id}: {e}")
                for _ in range(batch_size):
                    all_results[page_counter] = f"<!-- í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹¤íŒ¨ - ì›Œì»¤ {worker_id} -->"
                    page_counter += 1
        
        # ê²°ê³¼ ì¡°í•©
        markdown_content = []
        for page_num in sorted(all_results.keys()):
            if page_num > 1:
                markdown_content.append("\n---\n")
            markdown_content.append(f"<!-- í˜ì´ì§€ {page_num} -->\n")
            markdown_content.append(all_results[page_num])
        
        total_time = (datetime.now() - start_time).total_seconds()
        
        # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
        print(f"\nğŸ“Š í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"  â±ï¸ ì´ ì‹œê°„: {total_time:.2f}ì´ˆ ({total_time/60:.1f}ë¶„)")
        print(f"  ğŸš€ ì²˜ë¦¬ëŸ‰: {total_images / total_time:.2f} ì´ë¯¸ì§€/ì´ˆ")
        print(f"  ğŸ”’ ê²©ë¦¬ ìˆ˜ì¤€: ì™„ì „ í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬")
        print(f"  ğŸ“ˆ ë³‘ë ¬ íš¨ìœ¨ì„±: {len(batches)}ê°œ ë…ë¦½ í”„ë¡œì„¸ìŠ¤")
        print(f"  ğŸ¯ ë©”ëª¨ë¦¬ ê²©ë¦¬: í”„ë¡œì„¸ìŠ¤ë³„ ì™„ì „ ë¶„ë¦¬")
        
        self.stats.update({
            'total_images': total_images,
            'total_processing_time': total_time,
            'processes_used': len(batches),
            'throughput': total_images / total_time,
            'isolation_level': 'complete'
        })
        
        return "\n".join(markdown_content)
    
    def get_isolation_stats(self) -> Dict[str, Any]:
        """í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ í†µê³„"""
        return {
            'mode': 'process_isolated_parallel',
            'isolation_level': 'complete_process_separation',
            'gpu_count': self.resource_manager.device_count,
            'memory_isolation': True,
            'performance_stats': self.stats
        }
    
    def cleanup(self):
        """í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹œìŠ¤í…œ ì •ë¦¬"""
        print("ğŸ§¹ í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹œìŠ¤í…œ ì •ë¦¬ ì¤‘...")
        
        if self.process_pool:
            self.process_pool.shutdown(wait=True)
            self.process_pool = None
        
        self.workers_initialized = False
        print("âœ… í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")


async def main():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    client = ProcessIsolatedQwenClient()
    
    print("ğŸ§ª í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸")
    if await client.initialize_isolated_system():
        print("âœ… í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì„±ê³µ")
        
        stats = client.get_isolation_stats()
        print(f"ğŸ“Š ì‹œìŠ¤í…œ ì„¤ì •: {stats['mode']}")
        print(f"ğŸ”’ ê²©ë¦¬ ìˆ˜ì¤€: {stats['isolation_level']}")
        print(f"ğŸ¯ GPU ìˆ˜: {stats['gpu_count']}")
        
        client.cleanup()
    else:
        print("âŒ í”„ë¡œì„¸ìŠ¤ ê²©ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")


if __name__ == "__main__":
    asyncio.run(main())