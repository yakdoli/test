"""
Xinference APIë¥¼ ì‚¬ìš©í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ (ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤)
"""

import asyncio
import aiohttp
import json
import base64
import time
from pathlib import Path
from typing import List, Optional, Dict, Tuple
import config

class AsyncXinferenceClient:
    def __init__(self):
        self.base_url = config.XINFERENCE_BASE_URL
        self.model_name = config.XINFERENCE_MODEL_NAME
        self.model_uid = config.XINFERENCE_MODEL_UID
        self.max_concurrent = config.MAX_CONCURRENT_REQUESTS
        self.request_timeout = config.REQUEST_TIMEOUT
        self.retry_delay = config.RETRY_DELAY
        
        # ë™ì‹œ ìš”ì²­ ìˆ˜ ì œí•œì„ ìœ„í•œ ì„¸ë§ˆí¬ì–´
        self.semaphore = asyncio.Semaphore(self.max_concurrent)
        self.stats_lock = asyncio.Lock()
        self.stats = {}
        
        self.reset_stats()

    def reset_stats(self):
        """í†µê³„ ë°ì´í„°ë¥¼ ì´ˆê¸°í™”"""
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'total_time': 0,
            'concurrent_requests': 0
        }

    def encode_image_to_base64(self, image_path: Path) -> str:
        """ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    async def check_xinference_connection(self) -> bool:
        """Xinference ì„œë²„ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/v1/models", timeout=aiohttp.ClientTimeout(total=5)) as response:
                    return response.status == 200
        except Exception as e:
            print(f"âŒ Xinference ì—°ê²° ì‹¤íŒ¨: {e}")
            return False

    async def check_model_availability(self) -> bool:
        """ì§€ì •ëœ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•˜ê³  model_uid ì„¤ì •"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{self.base_url}/v1/models") as response:
                    if response.status == 200:
                        data = await response.json()
                        models = data.get('data', [])
                        for model in models:
                            if model.get('id', '').startswith(self.model_name):
                                self.model_uid = model.get('id')
                                return True
                    return False
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False


    def get_syncfusion_prompt(self) -> str:
        """Syncfusion SDK ë§¤ë‰´ì–¼ì— íŠ¹í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return """Convert this Syncfusion SDK documentation image to structured markdown format optimized for LLM fine-tuning and RAG applications.

CRITICAL REQUIREMENTS:

## Code Processing
- Extract ALL code snippets with proper language identification
- Preserve exact syntax, indentation, and formatting
- Use appropriate code blocks with language tags (```csharp, ```vb, ```xml, etc.)
- Maintain complete method signatures, parameter lists, and return types
- Include inline code elements using backticks for class names, properties, methods

## API Documentation Structure
- Identify and properly format: Classes, Namespaces, Methods, Properties, Events, Enums
- Use consistent heading hierarchy (# for main topics, ## for classes, ### for methods)
- Create clear parameter tables with: Name | Type | Description | Default Value
- Document return values with type and description
- Extract exception information if present

## Technical Content Enhancement
- Preserve all technical terminology exactly as written
- Maintain version-specific information and compatibility notes
- Include performance considerations and best practices
- Extract configuration settings and their valid values
- Document dependencies and required assemblies

## Structured Output Format
- Use descriptive headers that include class/namespace context
- Create linkable anchors for cross-references
- Format examples with clear "Example:" or "Usage:" headers
- Include "See Also" sections for related APIs
- Add metadata comments for categorization

## Content Completeness
- Extract ALL visible text without omission
- Preserve table structures with proper markdown formatting
- Maintain numbered/bulleted lists with correct nesting
- Include notes, warnings, and tips in appropriate callout format
- Capture image captions and figure references

## RAG Optimization
- Use semantic section breaks for better chunking
- Include contextual keywords for improved searchability
- Maintain hierarchical relationships between parent/child concepts
- Add implicit context where beneficial for standalone understanding

Focus on creating documentation that serves as high-quality training data for LLM fine-tuning while being immediately useful for RAG retrieval systems."""    
    async def convert_single_image(self, session: aiohttp.ClientSession, image_path: Path, page_num: int) -> Tuple[int, Optional[str]]:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ (Xinference API ì‚¬ìš©)
        """
        async with self.semaphore:
            async with self.stats_lock:
                self.stats['total_requests'] += 1
                self.stats['concurrent_requests'] += 1
            
            start_time = time.time()
            
            try:
                image_base64 = self.encode_image_to_base64(image_path)
                
                # Xinference OpenAI í˜¸í™˜ API ì‚¬ìš©
                payload = {
                    "model": self.model_uid or self.model_name,
                    "messages": [
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": self.get_syncfusion_prompt()
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/jpeg;base64,{image_base64}"
                                    }
                                }
                            ]
                        }
                    ],
                    "max_tokens": 4000,
                    "stream": False
                }
                
                max_retries = 3
                last_exception = None
                
                for attempt in range(max_retries):
                    try:
                        print(f"ğŸ”„ í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì‹œì‘ (ì‹œë„: {attempt + 1}/{max_retries})")
                        timeout = aiohttp.ClientTimeout(total=self.request_timeout)
                        
                        async with session.post(
                            f"{self.base_url}/v1/chat/completions",
                            json=payload,
                            timeout=timeout,
                            headers={"Content-Type": "application/json"}
                        ) as response:
                            
                            if response.status == 200:
                                result = await response.json()
                                markdown_text = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                                
                                if markdown_text.strip():  # ë¹ˆ ë‚´ìš© ê²€ì‚¬
                                    async with self.stats_lock:
                                        self.stats['successful_requests'] += 1
                                        self.stats['total_time'] += time.time() - start_time
                                    print(f"âœ… í˜ì´ì§€ {page_num} ì„±ê³µ ({len(markdown_text)} ë¬¸ì)")
                                    return page_num, markdown_text
                                else:
                                    print(f"âš ï¸ í˜ì´ì§€ {page_num} ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")
                                    last_exception = "Empty response received"
                            else:
                                response_text = await response.text()
                                error_msg = f"HTTP {response.status}: {response_text[:200]}"
                                print(f"âŒ API ì˜¤ë¥˜ (í˜ì´ì§€: {page_num}, ì‹œë„: {attempt + 1}): {error_msg}")
                                last_exception = error_msg
                                
                    except asyncio.TimeoutError as e:
                        error_msg = f"Timeout after {self.request_timeout}s"
                        print(f"â° íƒ€ì„ì•„ì›ƒ (í˜ì´ì§€: {page_num}, ì‹œë„: {attempt + 1}): {error_msg}")
                        last_exception = error_msg
                    except aiohttp.ClientError as e:
                        error_msg = f"Network error: {str(e)}"
                        print(f"ğŸ”Œ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ (í˜ì´ì§€: {page_num}, ì‹œë„: {attempt + 1}): {error_msg}")
                        last_exception = error_msg
                    except Exception as e:
                        error_msg = f"Unexpected error: {str(e)}"
                        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ (í˜ì´ì§€: {page_num}, ì‹œë„: {attempt + 1}): {error_msg}")
                        last_exception = error_msg
                    
                    # ì¬ì‹œë„ ëŒ€ê¸° (ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹Œ ê²½ìš°)
                    if attempt < max_retries - 1:
                        wait_time = self.retry_delay * (attempt + 1)
                        print(f"â³ {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                        await asyncio.sleep(wait_time)
                
                # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
                print(f"âŒ í˜ì´ì§€ {page_num} ìµœì¢… ì‹¤íŒ¨: {last_exception}")
                async with self.stats_lock:
                    self.stats['failed_requests'] += 1
                return page_num, None
                
            except Exception as e:
                print(f"âŒ ì‹¬ê°í•œ ì˜¤ë¥˜ (í˜ì´ì§€ {page_num}): {e}")
                async with self.stats_lock:
                    self.stats['failed_requests'] += 1
                return page_num, None
            finally:
                async with self.stats_lock:
                    self.stats['concurrent_requests'] -= 1
    
    async def convert_images_to_markdown_parallel(self, image_paths: List[Path]) -> str:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ë¹„ë™ê¸° ë³‘ë ¬ë¡œ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ (ê³ ê¸‰ ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§)
        """
        self.reset_stats()
        print(f"ğŸš€ ë¹„ë™ê¸° ì²˜ë¦¬ ì‹œì‘: {len(image_paths)}ê°œ í˜ì´ì§€, ìµœëŒ€ {self.max_concurrent}ê°œ ë™ì‹œ ì²˜ë¦¬")
        
        results = {}
        failed_pages = []
        start_time = time.time()
        
        # ì§„í–‰ìƒí™© ì¶”ì  ë³€ìˆ˜
        completed_count = 0
        total_pages = len(image_paths)
        last_progress_time = start_time
        
        # ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ë½
        progress_lock = asyncio.Lock()
        
        async def print_progress_stats():
            """ì£¼ê¸°ì ìœ¼ë¡œ ì§„í–‰ìƒí™©ê³¼ ì›Œì»¤ í†µê³„ë¥¼ ì¶œë ¥"""
            while completed_count < total_pages:
                await asyncio.sleep(10)  # 10ì´ˆë§ˆë‹¤ í†µê³„ ì¶œë ¥
                
                async with progress_lock:
                    if completed_count < total_pages:
                        elapsed_time = time.time() - start_time
                        progress_percent = (completed_count / total_pages) * 100
                        pages_per_sec = completed_count / elapsed_time if elapsed_time > 0 else 0
                        estimated_total_time = elapsed_time / completed_count * total_pages if completed_count > 0 else 0
                        remaining_time = estimated_total_time - elapsed_time
                        
                        print(f"\nğŸ“Š ì§„í–‰ìƒí™©: {completed_count}/{total_pages} ({progress_percent:.1f}%)")
                        print(f"â±ï¸ ê²½ê³¼ì‹œê°„: {elapsed_time/60:.1f}ë¶„, ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining_time/60:.1f}ë¶„")
                        print(f"ğŸ“ˆ ì²˜ë¦¬ì†ë„: {pages_per_sec:.1f} í˜ì´ì§€/ì´ˆ")
                        
                        print(f"ğŸ—ï¸ Xinference ì„œë²„: ì •ìƒ ì‘ë™ ì¤‘")
        
        async def process_single_task(session: aiohttp.ClientSession, image_path: Path, page_num: int):
            """ë‹¨ì¼ ì‘ì—… ì²˜ë¦¬ ë° ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸"""
            nonlocal completed_count, last_progress_time
            
            try:
                print(f"ğŸ¯ í˜ì´ì§€ {page_num} ì‘ì—… ì‹œì‘ ({image_path.name})")
                result = await self.convert_single_image(session, image_path, page_num)
                page_num_result, markdown_text = result
                
                async with progress_lock:
                    completed_count += 1
                    current_time = time.time()
                    
                    if markdown_text and markdown_text.strip():
                        results[page_num_result] = markdown_text
                        elapsed_time = current_time - start_time
                        progress_percent = (completed_count / total_pages) * 100
                        estimated_total_time = elapsed_time / completed_count * total_pages if completed_count > 0 else 0
                        remaining_time = max(0, estimated_total_time - elapsed_time)
                        
                        print(f"âœ… í˜ì´ì§€ {page_num_result} ì™„ë£Œ ({completed_count}/{total_pages}, {progress_percent:.1f}%) "
                              f"- ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining_time/60:.1f}ë¶„")
                        last_progress_time = current_time
                    else:
                        results[page_num_result] = f"<!-- í˜ì´ì§€ {page_num_result} ë³€í™˜ ì‹¤íŒ¨: ë¹ˆ ì‘ë‹µ -->"
                        failed_pages.append(page_num_result)
                        print(f"âŒ í˜ì´ì§€ {page_num_result} ì‹¤íŒ¨ ({completed_count}/{total_pages}) - ë¹ˆ ì‘ë‹µ")
                    
            except Exception as e:
                async with progress_lock:
                    completed_count += 1
                    results[page_num] = f"<!-- í˜ì´ì§€ {page_num} ë³€í™˜ ì‹¤íŒ¨: {str(e)} -->"
                    failed_pages.append(page_num)
                    print(f"âŒ í˜ì´ì§€ {page_num} ì˜ˆì™¸ ë°œìƒ: {str(e)} ({completed_count}/{total_pages})")
                    
            print(f"ğŸ í˜ì´ì§€ {page_num} ì‘ì—… ì™„ë£Œ")
        
        # aiohttp ì„¸ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰
        async with aiohttp.ClientSession() as session:
            # ëª¨ë“  ì‘ì—…ì„ ë¹„ë™ê¸° íƒœìŠ¤í¬ë¡œ ìƒì„±
            tasks = [
                process_single_task(session, path, i + 1)
                for i, path in enumerate(image_paths)
            ]
            
            print(f"ğŸ“‹ {len(tasks)}ê°œ ì‘ì—… ìƒì„± ì™„ë£Œ, ì‹¤í–‰ ì¤‘...")
            
            # ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì‹œì‘
            progress_monitor = asyncio.create_task(print_progress_stats())
            
            try:
                # ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰í•˜ë˜, ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
                print(f"â³ ëª¨ë“  ì‘ì—… ì‹¤í–‰ ëŒ€ê¸° ì¤‘...")
                results_list = await asyncio.gather(*tasks, return_exceptions=True)
                
                # ì˜ˆì™¸ê°€ ë°œìƒí•œ ì‘ì—…ë“¤ í™•ì¸
                for i, result in enumerate(results_list):
                    if isinstance(result, Exception):
                        page_num = i + 1
                        print(f"â— ì‘ì—… {page_num}ì—ì„œ ì˜ˆì™¸ ë°œìƒ: {result}")
                        async with progress_lock:
                            if page_num not in results:
                                results[page_num] = f"<!-- í˜ì´ì§€ {page_num} ë³€í™˜ ì‹¤íŒ¨: {str(result)} -->"
                                failed_pages.append(page_num)
                                
                print(f"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ: ì„±ê³µ {len(results) - len(failed_pages)}/{len(results)}")
                        
            finally:
                # ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬ ì¢…ë£Œ
                progress_monitor.cancel()
                try:
                    await progress_monitor
                except asyncio.CancelledError:
                    pass
        
        # ê²°ê³¼ë¥¼ í˜ì´ì§€ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ì—¬ ë§ˆí¬ë‹¤ìš´ ìƒì„±
        markdown_content = []
        for page_num in sorted(results.keys()):
            if page_num > 1:
                markdown_content.append("\n---\n")
            markdown_content.append(f"<!-- í˜ì´ì§€ {page_num} -->\n")
            markdown_content.append(results[page_num])
        
        total_time = time.time() - start_time
        
        print(f"\nğŸ“Š ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"  â±ï¸ ì´ ì‹œê°„: {total_time:.2f}ì´ˆ ({total_time/60:.1f}ë¶„)")
        print(f"  ğŸ“ˆ ì²˜ë¦¬ëŸ‰: {len(image_paths) / total_time:.2f} í˜ì´ì§€/ì´ˆ")
        print(f"  âœ… ì„±ê³µ: {self.stats['successful_requests']}/{self.stats['total_requests']}")
        print(f"  âŒ ì‹¤íŒ¨: {self.stats['failed_requests']}/{self.stats['total_requests']}")
        if self.stats['successful_requests'] > 0:
            avg_time = self.stats['total_time'] / self.stats['successful_requests']
            print(f"  âš¡ í‰ê·  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ")
        if failed_pages:
            print(f"  âš ï¸ ì‹¤íŒ¨í•œ í˜ì´ì§€: {sorted(failed_pages)}")
        
        # ìµœì¢… í†µê³„
        print(f"\nğŸ—ï¸ Xinference ì„œë²„ ì„±ëŠ¥ ìš”ì•½:")
        if self.stats['successful_requests'] > 0:
            avg_response_time = self.stats['total_time'] / self.stats['successful_requests']
            print(f"  {self.base_url}: {self.stats['successful_requests']}ê°œ ì„±ê³µ, í‰ê·  {avg_response_time:.1f}ì´ˆ")
        
        return "\n".join(markdown_content)
    
    def post_process_syncfusion_content(self, markdown_content: str, pdf_name: str) -> str:
        """Syncfusion SDK ë§¤ë‰´ì–¼ ì½˜í…ì¸  í›„ì²˜ë¦¬"""
        if not config.SYNCFUSION_MODE:
            return markdown_content
            
        processed_content = []
        
        if config.INCLUDE_METADATA:
            metadata = f"""
---
title: "{pdf_name} - Syncfusion SDK Documentation"
type: "api-documentation"
framework: "syncfusion"
version: "v11"
extracted_date: "{time.time()}"
optimized_for: ["llm-training", "rag-retrieval"]
async_parallel_processed: true
processing_stats:
  total_requests: {self.stats['total_requests']}
  successful_requests: {self.stats['successful_requests']}
  failed_requests: {self.stats['failed_requests']}
---

"""
            processed_content.append(metadata)
        
        processed_content.append(markdown_content)
        return '\n'.join(processed_content)

# í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
ParallelOllamaClient = AsyncXinferenceClient
AsyncParallelOllamaClient = AsyncXinferenceClient

async def main():
    """ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    client = AsyncXinferenceClient()
    
    if await client.check_xinference_connection():
        print("âœ… Xinference ì„œë²„ ì—°ê²° ì„±ê³µ")
        
        if await client.check_model_availability():
            print(f"âœ… ëª¨ë¸ '{client.model_name}' ì‚¬ìš© ê°€ëŠ¥ (UID: {client.model_uid})")
            print(f"ğŸ”§ ë¹„ë™ê¸° ì„¤ì •: ìµœëŒ€ {client.max_concurrent}ê°œ ë™ì‹œ ìš”ì²­")
        else:
            print(f"âŒ ëª¨ë¸ '{client.model_name}' ì‚¬ìš© ë¶ˆê°€ëŠ¥")
    else:
        print("âŒ Xinference ì„œë²„ ì—°ê²° ì‹¤íŒ¨")

if __name__ == "__main__":
    asyncio.run(main())
